{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b24169b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Corpus created successfully**\n",
      "**Dimension for Text features are (8279, 1367)**\n",
      "**Dimension for features data frame are (8279, 1373)**\n",
      "Removing columns [0] because they are of 'Unknown' type\n",
      "Generating pipelines to search over...\n",
      "1 pipelines ready for search.\n",
      "\n",
      "*****************************\n",
      "* Beginning pipeline search *\n",
      "*****************************\n",
      "\n",
      "Optimizing for Log Loss Binary. \n",
      "Lower score is better.\n",
      "\n",
      "Using SequentialEngine to train and score pipelines.\n",
      "Searching up to 1 batches for a total of 2 pipelines. \n",
      "Allowed model families: xgboost\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09035a0304d94dab8d2926ee58ad8822",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'mode': 'lines+markers',\n",
       "              'name': 'Best Score',\n",
       "              'type'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Baseline Pipeline: Mode Baseline Binary Classification Pipeline\n",
      "Mode Baseline Binary Classification Pipeline:\n",
      "\tStarting cross validation\n",
      "\tFinished cross validation - mean Log Loss Binary: 16.026\n",
      "\n",
      "*****************************\n",
      "* Evaluating Batch Number 1 *\n",
      "*****************************\n",
      "\n",
      "XGBoost Classifier w/ Label Encoder + Drop Columns Transformer + Imputer + One Hot Encoder:\n",
      "\tStarting cross validation\n",
      "\tFinished cross validation - mean Log Loss Binary: 0.243\n",
      "\n",
      "Search finished after 09:28            \n",
      "Best pipeline: XGBoost Classifier w/ Label Encoder + Drop Columns Transformer + Imputer + One Hot Encoder\n",
      "Best pipeline Log Loss Binary: 0.242550\n",
      "\n",
      "**********************************************************************************************\n",
      "* XGBoost Classifier w/ Label Encoder + Drop Columns Transformer + Imputer + One Hot Encoder *\n",
      "**********************************************************************************************\n",
      "\n",
      "Problem Type: binary\n",
      "Model Family: XGBoost\n",
      "\n",
      "Pipeline Steps\n",
      "==============\n",
      "1. Label Encoder\n",
      "\t * positive_label : None\n",
      "2. Drop Columns Transformer\n",
      "\t * columns : [0]\n",
      "3. Imputer\n",
      "\t * categorical_impute_strategy : most_frequent\n",
      "\t * numeric_impute_strategy : mean\n",
      "\t * categorical_fill_value : None\n",
      "\t * numeric_fill_value : None\n",
      "4. One Hot Encoder\n",
      "\t * top_n : 10\n",
      "\t * features_to_encode : None\n",
      "\t * categories : None\n",
      "\t * drop : if_binary\n",
      "\t * handle_unknown : ignore\n",
      "\t * handle_missing : error\n",
      "5. XGBoost Classifier\n",
      "\t * eta : 0.1\n",
      "\t * max_depth : 6\n",
      "\t * min_child_weight : 1\n",
      "\t * n_estimators : 100\n",
      "\t * n_jobs : -1\n",
      "\t * eval_metric : logloss\n",
      "\n",
      "Training\n",
      "========\n",
      "Training for binary problems.\n",
      "Total training time (including CV): 539.7 seconds\n",
      "\n",
      "Cross Validation\n",
      "----------------\n",
      "             Log Loss Binary  MCC Binary  Gini   AUC  Precision    F1  Balanced Accuracy Binary  Accuracy Binary # Training # Validation\n",
      "0                      0.249       0.790 0.922 0.961      0.883 0.888                     0.895            0.895      4,415        2,208\n",
      "1                      0.232       0.826 0.944 0.972      0.893 0.908                     0.914            0.913      4,415        2,208\n",
      "2                      0.246       0.805 0.926 0.963      0.885 0.896                     0.903            0.903      4,416        2,207\n",
      "mean                   0.243       0.807 0.931 0.965      0.887 0.897                     0.904            0.904          -            -\n",
      "std                    0.009       0.018 0.012 0.006      0.005 0.010                     0.009            0.009          -            -\n",
      "coef of var            0.039       0.023 0.013 0.006      0.006 0.011                     0.010            0.010          -            -\n"
     ]
    }
   ],
   "source": [
    "# importing required libraries\n",
    "import pandas as pd\n",
    "import evalml\n",
    "\n",
    "\n",
    "\n",
    "# dataset = pd.read_excel('TestData _MasterInput_0.4 - Copy.xlsx')\n",
    "# dataset = pd.read_excel('test8.2.xltx')\n",
    "# dataset = dataset.tail(60)\n",
    "# dataset = pd.read_excel('SampleTestData V0.2 113.xlsx')\n",
    "# dataset = pd.read_excel('Dummy Dataset0.3.xlsx')\n",
    "# dataset = pd.read_excel('SDMaster_input_Sheet.xlsx')\n",
    "dataset = pd.read_excel('InputSheet_Train.xlsx')\n",
    "final = dataset\n",
    "\n",
    "# pred_data = pd.read_excel('InputSheet_Train_latest.xlsx')\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "labelencoder = LabelEncoder()\n",
    "dataset['Release ID'] = labelencoder.fit_transform(dataset['Release ID'].astype(str))\n",
    "# pred_data['Release ID'] = labelencoder.fit_transform(pred_data['Release ID'].astype(str))\n",
    "dataset.head()\n",
    "dataset.reset_index(inplace=True)\n",
    "\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "corpus_title = []\n",
    "pstem = PorterStemmer()\n",
    "for i in range(dataset['Test Case Title'].shape[0]):\n",
    "    # Remove unwanted words\n",
    "    text = re.sub(\"[^a-zA-Z]\", ' ', dataset['Test Case Title'][i])\n",
    "    # Transform words to lowercase\n",
    "    text = text.lower()\n",
    "    text = text.split()\n",
    "    # Remove stopwords then Stemming it\n",
    "    text = [pstem.stem(word) for word in text if not word in set(stopwords.words('english'))]\n",
    "    text = ' '.join(text)\n",
    "    # Append cleaned tweet to corpus\n",
    "    corpus_title.append(text)\n",
    "\n",
    "print(\"**Corpus created successfully**\")\n",
    "\n",
    "\n",
    "# pred_corpus_title = []\n",
    "# pstem = PorterStemmer()\n",
    "# for i in range(pred_data['Test Case Title'].shape[0]):\n",
    "#     # Remove unwanted words\n",
    "#     text = re.sub(\"[^a-zA-Z]\", ' ', pred_data['Test Case Title'][i])\n",
    "#     # Transform words to lowercase\n",
    "#     text = text.lower()\n",
    "#     text = text.split()\n",
    "#     # Remove stopwords then Stemming it\n",
    "#     text = [pstem.stem(word) for word in text if not word in set(stopwords.words('english'))]\n",
    "#     text = ' '.join(text)\n",
    "#     # Append cleaned tweet to corpus\n",
    "#     pred_corpus_title.append(text)\n",
    "\n",
    "# print(\"**Prediction Corpus created successfully**\")\n",
    "\n",
    "# Creating the Bag of Words model\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer()\n",
    "text_vectors= cv.fit_transform(corpus_title).toarray()\n",
    "# pred_text_vectors= cv.fit_transform(pred_corpus_title).toarray()\n",
    "\n",
    "#Convert text vectors into data frame\n",
    "text_vectors_df=pd.DataFrame(text_vectors)\n",
    "print(\"**Dimension for Text features are {}**\".format(text_vectors_df.shape))\n",
    "\n",
    "# pred_text_vectors_df=pd.DataFrame(pred_text_vectors)\n",
    "# print(\"**Dimension for Prediction Text features are {}**\".format(pred_text_vectors_df.shape))\n",
    "\n",
    "#Getting Target variable into Y variable\n",
    "y=dataset[['Target']].values\n",
    "#Converting 2 dimensional y and y_pred array into single dimension\n",
    "y=y.ravel()\n",
    "\n",
    "#Removing 'Target' and 'TestCaseTitle' columns from actual dataset\n",
    "dataset=dataset.drop(['index','Target','Test Case Title'],axis=1)\n",
    "# pred_data=pred_data.drop(['Test Case Title'], axis=1)\n",
    "#Creating new data frame with all categorical feature and Text features for training classifier models\n",
    "X=pd.concat([dataset,text_vectors_df],axis=1).values\n",
    "print(\"**Dimension for features data frame are {}**\".format(X.shape))\n",
    "\n",
    "# pred_X=pd.concat([pred_data,pred_text_vectors_df],axis=1).values\n",
    "# print(\"**Dimension for pred features data frame are {}**\".format(pred_X.shape))\n",
    "\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)\n",
    "X_train, X_test, y_train, y_test = evalml.preprocessing.split_data(X, y, problem_type='binary', test_size=0.2, random_seed=0)\n",
    "final_data = X_test\n",
    "# EvalMl code\n",
    "\n",
    "automl = evalml.automl.AutoMLSearch(X_train=X_train, y_train=y_train, problem_type='binary',verbose=True,max_batches=1,\n",
    "                                    allowed_model_families=[\"XGBOOST\"])\n",
    "automl.search()\n",
    "\n",
    "from evalml.model_understanding.graphs import confusion_matrix\n",
    "import pickle\n",
    "\n",
    "\n",
    "best_pipeline = automl.best_pipeline\n",
    "automl.describe_pipeline(automl.rankings.iloc[0][\"id\"])\n",
    "\n",
    "scores = best_pipeline.score(X_test, y_test,  objectives=evalml.objectives.get_core_objectives('binary'))\n",
    "\n",
    "\n",
    "# print(f'Accuracy Binary: {scores[\"Accuracy Binary\"]}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0f5a355f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Prediction Corpus created successfully**\n",
      "**Dimension for Prediction Text features are (810, 1367)**\n",
      "**Dimension for pred features data frame are (810, 1373)**\n"
     ]
    }
   ],
   "source": [
    "pred_data = pd.read_excel('InputSheet_Train_latest.xlsx')\n",
    "# pred_data['Release ID'] = labelencoder.transform(pred_data['Release ID'].astype(str))\n",
    "\n",
    "\n",
    "pred_corpus_title = []\n",
    "# pstem = PorterStemmer()\n",
    "for i in range(pred_data['Test Case Title'].shape[0]):\n",
    "    # Remove unwanted words\n",
    "    text = re.sub(\"[^a-zA-Z]\", ' ', pred_data['Test Case Title'][i])\n",
    "    # Transform words to lowercase\n",
    "    text = text.lower()\n",
    "    text = text.split()\n",
    "    # Remove stopwords then Stemming it\n",
    "    text = [pstem.stem(word) for word in text if not word in set(stopwords.words('english'))]\n",
    "    text = ' '.join(text)\n",
    "    # Append cleaned tweet to corpus\n",
    "    pred_corpus_title.append(text)\n",
    "\n",
    "print(\"**Prediction Corpus created successfully**\")\n",
    "\n",
    "# Creating the Bag of Words model\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# cv = CountVectorizer()\n",
    "pred_text_vectors= cv.transform(pred_corpus_title).toarray()\n",
    "\n",
    "#Convert text vectors into data frame\n",
    "pred_text_vectors_df=pd.DataFrame(pred_text_vectors)\n",
    "print(\"**Dimension for Prediction Text features are {}**\".format(pred_text_vectors_df.shape))\n",
    "\n",
    "#Getting Target variable into Y variable\n",
    "# y=dataset[['Target']].values\n",
    "# #Converting 2 dimensional y and y_pred array into single dimension\n",
    "# y=y.ravel()\n",
    "\n",
    "#Removing 'Target' and 'TestCaseTitle' columns from actual dataset\n",
    "pred_data=pred_data.drop(['Test Case Title'], axis=1)\n",
    "#Creating new data frame with all categorical feature and Text features for training classifier models\n",
    "pred_X=pd.concat([pred_data,pred_text_vectors_df],axis=1).values\n",
    "print(\"**Dimension for pred features data frame are {}**\".format(pred_X.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a4d78796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.365034</td>\n",
       "      <td>0.634966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.475210</td>\n",
       "      <td>0.524790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.432381</td>\n",
       "      <td>0.567619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.432381</td>\n",
       "      <td>0.567619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.567005</td>\n",
       "      <td>0.432995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>805</th>\n",
       "      <td>0.995007</td>\n",
       "      <td>0.004993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>806</th>\n",
       "      <td>0.997626</td>\n",
       "      <td>0.002374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>807</th>\n",
       "      <td>0.997699</td>\n",
       "      <td>0.002301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808</th>\n",
       "      <td>0.996236</td>\n",
       "      <td>0.003764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>809</th>\n",
       "      <td>0.996236</td>\n",
       "      <td>0.003764</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>810 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1\n",
       "0    0.365034  0.634966\n",
       "1    0.475210  0.524790\n",
       "2    0.432381  0.567619\n",
       "3    0.432381  0.567619\n",
       "4    0.567005  0.432995\n",
       "..        ...       ...\n",
       "805  0.995007  0.004993\n",
       "806  0.997626  0.002374\n",
       "807  0.997699  0.002301\n",
       "808  0.996236  0.003764\n",
       "809  0.996236  0.003764\n",
       "\n",
       "[810 rows x 2 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_pipeline.save(\"model.pkl\")\n",
    "# loading the model saved in pickel file\n",
    "check_model = automl.load('model.pkl')\n",
    "# predicting testing data\n",
    "check_model.predict_proba(pred_X)#.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4f991d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8279, 1374)\n",
      "---------------------\n",
      "(1656, 1374)\n",
      "---------------------\n",
      "(810, 1373)\n",
      "      index           ID  Release ID TestCase Priority Any Defects  \\\n",
      "0         0   AZA-T56074           2             Minor          No   \n",
      "1         1   AZA-T54587           2             Minor          No   \n",
      "2         2   AZA-T58184           2             Minor          No   \n",
      "3         3   AZA-T50499           2              High          No   \n",
      "4         4   AZA-T50493           2              High          No   \n",
      "...     ...          ...         ...               ...         ...   \n",
      "8274   8274  AZA-T102825           2              High          No   \n",
      "8275   8275  AZA-T108184           2              High          No   \n",
      "8276   8276  AZA-T102823           2              High          No   \n",
      "8277   8277  AZA-T108183           2              High          No   \n",
      "8278   8278  AZA-T108181           2              High          No   \n",
      "\n",
      "                  Module  In scope OEs  \n",
      "0     Product & Contract    GH (Ghana)  \n",
      "1     Product & Contract    GH (Ghana)  \n",
      "2     Product & Contract    GH (Ghana)  \n",
      "3     Product & Contract    GH (Ghana)  \n",
      "4     Product & Contract    GH (Ghana)  \n",
      "...                  ...           ...  \n",
      "8274              Output  MA (Morocco)  \n",
      "8275  Product & Contract  MA (Morocco)  \n",
      "8276              Output  MA (Morocco)  \n",
      "8277  Product & Contract  MA (Morocco)  \n",
      "8278  Product & Contract  MA (Morocco)  \n",
      "\n",
      "[8279 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(\"---------------------\")\n",
    "print(X_test.shape)\n",
    "print(\"---------------------\")\n",
    "print(pred_X.shape)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4fb6ddbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 'AZA-T56074' 2 ... 0 0 0]\n",
      " [1 'AZA-T54587' 2 ... 0 0 0]\n",
      " [2 'AZA-T58184' 2 ... 0 0 0]\n",
      " ...\n",
      " [8276 'AZA-T102823' 2 ... 0 0 0]\n",
      " [8277 'AZA-T108183' 2 ... 0 0 0]\n",
      " [8278 'AZA-T108181' 2 ... 0 0 0]]\n",
      "---------------------\n",
      "[['AZA-T84771' 'Release 19' 'Major' ... 0 0 0]\n",
      " ['AZA-T73579' 'Release 19' 'Major' ... 0 0 0]\n",
      " ['AZA-T86726' 'Release 19' 'Major' ... 0 0 0]\n",
      " ...\n",
      " ['AZA-T110513' 'Release 19' 'High' ... 0 0 0]\n",
      " ['AZA-T109281' 'Release 19' 'High' ... 0 0 0]\n",
      " ['AZA-T109280' 'Release 19' 'High' ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(X)\n",
    "print(\"---------------------\")\n",
    "print(pred_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98e19857",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2855    0\n",
       "782     1\n",
       "6712    0\n",
       "8108    0\n",
       "4988    1\n",
       "       ..\n",
       "7343    0\n",
       "6242    1\n",
       "7245    0\n",
       "2444    1\n",
       "3276    0\n",
       "Name: 1, Length: 1656, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y_pred = best_pipeline.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b6842d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_pipeline.predict(pred_X)\n",
    "\n",
    "#writing file temporary format\n",
    "output = pd.DataFrame(y_pred)\n",
    "output.rename(columns={1:'Target'},inplace=True)\n",
    "# output = pd.concat([dataset1[dataset1.ID.isin(pd.DataFrame(X_test)[1])], output], axis=1)\n",
    "output = pd.concat([pd.DataFrame(X)[[1,7,9]],output], axis=1)\n",
    "\n",
    "output.dropna(inplace=True)\n",
    "output.drop_duplicates(subset=[1], inplace=True)\n",
    "output.rename(columns={1:'ID',7:\"Modules\",9:\"Scripts\",'Target':\"Target\"},inplace=True)\n",
    "master_dataframe = output\n",
    "# master_dataframe = master_dataframe.astype({\"ID\": int})\n",
    "\n",
    "master_dataframe = pd.merge(left=final[['ID', 'Test Case Title']], right=master_dataframe, how='right', left_on='ID', right_on='ID')\n",
    "master_dataframe.drop_duplicates(subset=['ID'], inplace=True)\n",
    "delete_row = master_dataframe[master_dataframe[\"Target\"]==0].index\n",
    "master_dataframe = master_dataframe.drop(delete_row)\n",
    "\n",
    "#Final format\n",
    "\n",
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "timestamp = str(now.strftime(\"%Y%m%d_%H-%M-%S\"))\n",
    "date = str(now.strftime(\"%Y%m%d\"))\n",
    "\n",
    "#creating output folder as per the today's date\n",
    "import os\n",
    "output_folder = '../'+'output_'+date\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "\n",
    "###Final output : No of TCS for regression testing send to excel\n",
    "final_output_file = output_folder + '/FinalOutput_'+timestamp+'.xlsx'\n",
    "writer = pd.ExcelWriter(final_output_file, engine='xlsxwriter')\n",
    "\n",
    "\n",
    "pd.DataFrame(master_dataframe.iloc[:, 0:3]).to_excel(writer,\n",
    "    sheet_name=\"Master_Output\",\n",
    "    index=False)\n",
    "\n",
    "df = master_dataframe\n",
    "m_tc = []\n",
    "a_tc = []\n",
    "# if limit == 0:\n",
    "for i in range(len(df.iloc[:,0])):\n",
    "    if df.iloc[i,3] == \"Manual Testing\":\n",
    "        m_tc.append((df.iloc[i,0], df.iloc[i,1], df.iloc[i,2]))\n",
    "        # m_tc.append((df.iloc[i,0], df.iloc[i,1]))\n",
    "    else:\n",
    "        a_tc.append((df.iloc[i,2], df.iloc[i,3]))\n",
    "        # a_tc.append((df.iloc[i,1], df.iloc[i,2]))\n",
    "\n",
    "\n",
    "df_auto = pd.DataFrame(set(a_tc), columns=[\"Module\", \"Automation Script Name\"])\n",
    "df_auto.drop_duplicates(subset=[\"Automation Script Name\"],inplace=True)\n",
    "df_auto.index += 1\n",
    "df_auto.index.name=\"S.No.\"\n",
    "df_auto.to_excel(writer, sheet_name=\"Automation_Scripts\")\n",
    "df_manual = pd.DataFrame(m_tc, columns=[\"Test ID\",\"Test Case Title\", \"Module\"])\n",
    "# df_manual = pd.DataFrame(m_tc, columns=[\"Test ID\",\"Module\"])\n",
    "df_manual.index += 1\n",
    "df_manual.index.name = \"S.No.\"\n",
    "df_manual.to_excel(writer, sheet_name=\"Manual_TC\")\n",
    "\n",
    "writer.save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8898aba5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1364</th>\n",
       "      <th>1365</th>\n",
       "      <th>1366</th>\n",
       "      <th>1367</th>\n",
       "      <th>1368</th>\n",
       "      <th>1369</th>\n",
       "      <th>1370</th>\n",
       "      <th>1371</th>\n",
       "      <th>1372</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AZA-T56074</td>\n",
       "      <td>2</td>\n",
       "      <td>Minor</td>\n",
       "      <td>No</td>\n",
       "      <td>Product &amp; Contract</td>\n",
       "      <td>GH (Ghana)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AZA-T54587</td>\n",
       "      <td>2</td>\n",
       "      <td>Minor</td>\n",
       "      <td>No</td>\n",
       "      <td>Product &amp; Contract</td>\n",
       "      <td>GH (Ghana)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AZA-T58184</td>\n",
       "      <td>2</td>\n",
       "      <td>Minor</td>\n",
       "      <td>No</td>\n",
       "      <td>Product &amp; Contract</td>\n",
       "      <td>GH (Ghana)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AZA-T50499</td>\n",
       "      <td>2</td>\n",
       "      <td>High</td>\n",
       "      <td>No</td>\n",
       "      <td>Product &amp; Contract</td>\n",
       "      <td>GH (Ghana)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AZA-T50493</td>\n",
       "      <td>2</td>\n",
       "      <td>High</td>\n",
       "      <td>No</td>\n",
       "      <td>Product &amp; Contract</td>\n",
       "      <td>GH (Ghana)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8274</th>\n",
       "      <td>AZA-T102825</td>\n",
       "      <td>2</td>\n",
       "      <td>High</td>\n",
       "      <td>No</td>\n",
       "      <td>Output</td>\n",
       "      <td>MA (Morocco)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8275</th>\n",
       "      <td>AZA-T108184</td>\n",
       "      <td>2</td>\n",
       "      <td>High</td>\n",
       "      <td>No</td>\n",
       "      <td>Product &amp; Contract</td>\n",
       "      <td>MA (Morocco)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8276</th>\n",
       "      <td>AZA-T102823</td>\n",
       "      <td>2</td>\n",
       "      <td>High</td>\n",
       "      <td>No</td>\n",
       "      <td>Output</td>\n",
       "      <td>MA (Morocco)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8277</th>\n",
       "      <td>AZA-T108183</td>\n",
       "      <td>2</td>\n",
       "      <td>High</td>\n",
       "      <td>No</td>\n",
       "      <td>Product &amp; Contract</td>\n",
       "      <td>MA (Morocco)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8278</th>\n",
       "      <td>AZA-T108181</td>\n",
       "      <td>2</td>\n",
       "      <td>High</td>\n",
       "      <td>No</td>\n",
       "      <td>Product &amp; Contract</td>\n",
       "      <td>MA (Morocco)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8279 rows × 1374 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0  1      2   3                   4             5  6  7  8  9  \\\n",
       "0      AZA-T56074  2  Minor  No  Product & Contract    GH (Ghana)  0  0  0  0   \n",
       "1      AZA-T54587  2  Minor  No  Product & Contract    GH (Ghana)  0  0  0  0   \n",
       "2      AZA-T58184  2  Minor  No  Product & Contract    GH (Ghana)  0  0  0  0   \n",
       "3      AZA-T50499  2   High  No  Product & Contract    GH (Ghana)  0  0  0  0   \n",
       "4      AZA-T50493  2   High  No  Product & Contract    GH (Ghana)  0  0  0  0   \n",
       "...           ... ..    ...  ..                 ...           ... .. .. .. ..   \n",
       "8274  AZA-T102825  2   High  No              Output  MA (Morocco)  0  0  0  0   \n",
       "8275  AZA-T108184  2   High  No  Product & Contract  MA (Morocco)  0  0  0  0   \n",
       "8276  AZA-T102823  2   High  No              Output  MA (Morocco)  0  0  0  0   \n",
       "8277  AZA-T108183  2   High  No  Product & Contract  MA (Morocco)  0  0  0  0   \n",
       "8278  AZA-T108181  2   High  No  Product & Contract  MA (Morocco)  0  0  0  0   \n",
       "\n",
       "      ... 1364 1365 1366 1367 1368 1369 1370 1371 1372 Target  \n",
       "0     ...    0    0    0    0    0    0    0    0    0    1.0  \n",
       "1     ...    0    0    0    0    0    0    0    0    0    0.0  \n",
       "2     ...    0    0    0    0    0    0    0    0    0    0.0  \n",
       "3     ...    0    0    0    0    0    0    0    0    0    0.0  \n",
       "4     ...    0    0    0    0    0    0    0    0    0    0.0  \n",
       "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...    ...  \n",
       "8274  ...    0    0    0    0    0    0    0    0    0    NaN  \n",
       "8275  ...    0    0    0    0    0    0    0    0    0    NaN  \n",
       "8276  ...    0    0    0    0    0    0    0    0    0    NaN  \n",
       "8277  ...    0    0    0    0    0    0    0    0    0    NaN  \n",
       "8278  ...    0    0    0    0    0    0    0    0    0    NaN  \n",
       "\n",
       "[8279 rows x 1374 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = pd.DataFrame(y_pred)\n",
    "output.rename(columns={1:'Target'},inplace=True)\n",
    "# output = pd.concat([dataset1[dataset1.ID.isin(pd.DataFrame(X_test)[1])], output], axis=1)\n",
    "output = pd.concat([pd.DataFrame(X)[[0,4,5]],output], axis=1)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04e5b54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
