{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1abfd33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evalml\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "97c537d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Release ID', 'Test Case Title ', 'Test Case Priority',\n",
      "       'Linked Defects', 'Severity of Defects', 'Automation Status',\n",
      "       'Error Prone Test case', 'Module'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel('SampleTestData1.xlsx', index_col=0)\n",
    "# df = pd.read_excel('Defects_HRT.xlsx')#, index_col=1)\n",
    "print(df.columns)\n",
    "df.dropna(inplace=True)\n",
    "# df= df.head(500)\n",
    "\n",
    "# r = pd.concat([df,df,df])\n",
    "# r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "95f65a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.drop(columns=[\"Assigned To\", \"Detected By\"],inplace=True)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a8b60962",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X=df.drop(columns = ['Test Case Title '])#,axis=1)\n",
    "# X=df.drop(columns = ['Summary','Test Cycle','Defect ID'])\n",
    "y=df['Test Case Title ']\n",
    "# y=df['Summary']\n",
    "\n",
    "# print(X)\n",
    "# print(\"-------\")\n",
    "# print(y)\n",
    "\n",
    "X_train = X\n",
    "\n",
    "y_train = y\n",
    "\n",
    "# \n",
    "# X_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e4f157c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_holdout, y_train, y_holdout = evalml.preprocessing.split_data(X, y, problem_type='multiclass', test_size=0.2, random_seed=0)\n",
    "\n",
    "# df= pd.read_csv(\"https://raw.githubusercontent.com/sumukhakaparthi/Wine-Quality/master/winequality_edited.csv\")\n",
    "# X=df.drop('quality',axis=1)\n",
    "# y=df['quality']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "27284019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using default limit of max_batches=1.\n",
      "\n",
      "Generating pipelines to search over...\n",
      "8 pipelines ready for search.\n",
      "\n",
      "*****************************\n",
      "* Beginning pipeline search *\n",
      "*****************************\n",
      "\n",
      "Optimizing for Log Loss Multiclass. \n",
      "Lower score is better.\n",
      "\n",
      "Using SequentialEngine to train and score pipelines.\n",
      "Searching up to 1 batches for a total of 9 pipelines. \n",
      "Allowed model families: linear_model, linear_model, xgboost, lightgbm, catboost, random_forest, decision_tree, extra_trees\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "110a5fff1e3840aca95ecc5a3b14f69a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'mode': 'lines+markers',\n",
       "              'name': 'Best Score',\n",
       "              'type'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Baseline Pipeline: Mode Baseline Multiclass Classification Pipeline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\SmartTest\\lib\\site-packages\\sklearn\\model_selection\\_split.py:680: UserWarning:\n",
      "\n",
      "The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Missing target values in the training set after data split: {38, 43, 44, 46, 47, 60, 63, 51, 55, 54, 23, 26, 28, 29, 31}. Missing target values in the validation set after data split: {18, 20, 21, 22, 24, 25, 27, 30, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 45, 48, 49, 50, 52, 53, 56, 57, 58, 59, 61, 62, 64}.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8492/2489956329.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m automl = evalml.automl.AutoMLSearch(X_train=X, y_train=y, problem_type='multiclass',\n\u001b[0;32m      8\u001b[0m                                     verbose=True,data_splitter=None)\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mautoml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\SmartTest\\lib\\site-packages\\evalml\\automl\\automl_search.py\u001b[0m in \u001b[0;36msearch\u001b[1;34m(self, show_iteration_plot)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 885\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_add_baseline_pipelines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    886\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_keyboard_interrupt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\SmartTest\\lib\\site-packages\\evalml\\automl\\automl_search.py\u001b[0m in \u001b[0;36m_add_baseline_pipelines\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1109\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautoml_config\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbaseline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1110\u001b[0m         )\n\u001b[1;32m-> 1111\u001b[1;33m         \u001b[0mevaluation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcomputation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1112\u001b[0m         data, pipeline, job_log = (\n\u001b[0;32m   1113\u001b[0m             \u001b[0mevaluation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"scores\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\SmartTest\\lib\\site-packages\\evalml\\automl\\engine\\sequential_engine.py\u001b[0m in \u001b[0;36mget_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     45\u001b[0m             \u001b[0mComputation\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m         \"\"\"\n\u001b[1;32m---> 47\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwork\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcancel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\SmartTest\\lib\\site-packages\\evalml\\automl\\engine\\engine_base.py\u001b[0m in \u001b[0;36mevaluate_pipeline\u001b[1;34m(pipeline, automl_config, X, y, logger)\u001b[0m\n\u001b[0;32m    318\u001b[0m         \u001b[0mfull_X_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    319\u001b[0m         \u001b[0mfull_y_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 320\u001b[1;33m         \u001b[0mlogger\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogger\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    321\u001b[0m     )\n\u001b[0;32m    322\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\SmartTest\\lib\\site-packages\\evalml\\automl\\engine\\engine_base.py\u001b[0m in \u001b[0;36mtrain_and_score_pipeline\u001b[1;34m(pipeline, automl_config, full_X_train, full_y_train, logger)\u001b[0m\n\u001b[0;32m    199\u001b[0m             )\n\u001b[0;32m    200\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdiff_string\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdiff_string\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m         objectives_to_score = [\n\u001b[0;32m    203\u001b[0m             \u001b[0mautoml_config\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobjective\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mException\u001b[0m: Missing target values in the training set after data split: {38, 43, 44, 46, 47, 60, 63, 51, 55, 54, 23, 26, 28, 29, 31}. Missing target values in the validation set after data split: {18, 20, 21, 22, 24, 25, 27, 30, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 45, 48, 49, 50, 52, 53, 56, 57, 58, 59, 61, 62, 64}."
     ]
    }
   ],
   "source": [
    "# from sklearn.model_selection import KFold, StratifiedKFold\n",
    "# StratifiedKFold(\n",
    "#             n_splits=1, random_state=42)#, shuffle=shuffle\n",
    "        \n",
    "\n",
    "\n",
    "automl = evalml.automl.AutoMLSearch(X_train=X, y_train=y, problem_type='multiclass',\n",
    "                                    verbose=True,data_splitter=None)\n",
    "automl.search()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b5885bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*********************************************************************************************************************\n",
      "* LightGBM Classifier w/ Label Encoder + DateTime Featurization Component + Imputer + One Hot Encoder + Oversampler *\n",
      "*********************************************************************************************************************\n",
      "\n",
      "Problem Type: multiclass\n",
      "Model Family: LightGBM\n",
      "\n",
      "Pipeline Steps\n",
      "==============\n",
      "1. Label Encoder\n",
      "\t * positive_label : None\n",
      "2. DateTime Featurization Component\n",
      "\t * features_to_extract : ['year', 'month', 'day_of_week', 'hour']\n",
      "\t * encode_as_categories : False\n",
      "\t * date_index : None\n",
      "3. Imputer\n",
      "\t * categorical_impute_strategy : most_frequent\n",
      "\t * numeric_impute_strategy : mean\n",
      "\t * categorical_fill_value : None\n",
      "\t * numeric_fill_value : None\n",
      "4. One Hot Encoder\n",
      "\t * top_n : 10\n",
      "\t * features_to_encode : None\n",
      "\t * categories : None\n",
      "\t * drop : if_binary\n",
      "\t * handle_unknown : ignore\n",
      "\t * handle_missing : error\n",
      "5. Oversampler\n",
      "\t * sampling_ratio : 0.25\n",
      "\t * k_neighbors_default : 5\n",
      "\t * n_jobs : -1\n",
      "\t * sampling_ratio_dict : None\n",
      "\t * categorical_features : [5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]\n",
      "\t * k_neighbors : 1\n",
      "6. LightGBM Classifier\n",
      "\t * boosting_type : gbdt\n",
      "\t * learning_rate : 0.1\n",
      "\t * n_estimators : 100\n",
      "\t * max_depth : 0\n",
      "\t * num_leaves : 31\n",
      "\t * min_child_samples : 20\n",
      "\t * n_jobs : -1\n",
      "\t * bagging_freq : 0\n",
      "\t * bagging_fraction : 0.9\n",
      "\n",
      "Training\n",
      "========\n",
      "Training for multiclass problems.\n",
      "Total training time (including CV): 6.8 seconds\n",
      "\n",
      "Cross Validation\n",
      "----------------\n",
      "             Log Loss Multiclass  MCC Multiclass  AUC Weighted  AUC Macro  AUC Micro  Precision Weighted  Precision Macro  Precision Micro  F1 Weighted  F1 Macro  F1 Micro  Balanced Accuracy Multiclass  Accuracy Multiclass # Training # Validation\n",
      "0                          0.445           0.793         0.995      0.995      0.998               0.686            0.599            0.796        0.727     0.636     0.796                         0.704                0.796        226          113\n",
      "1                          0.444           0.766         0.995      0.995      0.998               0.691            0.604            0.770        0.713     0.631     0.770                         0.701                0.770        226          113\n",
      "2                          0.431           0.784         0.995      0.995      0.998               0.701            0.606            0.788        0.730     0.637     0.788                         0.700                0.788        226          113\n",
      "mean                       0.440           0.781         0.995      0.995      0.998               0.693            0.603            0.785        0.723     0.635     0.785                         0.702                0.785          -            -\n",
      "std                        0.008           0.014         0.000      0.000      0.000               0.008            0.004            0.014        0.009     0.003     0.014                         0.002                0.014          -            -\n",
      "coef of var                0.018           0.018         0.000      0.000      0.000               0.011            0.006            0.017        0.013     0.005     0.017                         0.003                0.017          -            -\n",
      "Accuracy Binary: 0.7964601769911505\n",
      "Prdiction is ID\n",
      "654    Verify that functionlity A is working as expec...\n",
      "53         Verify application performance is as expected\n",
      "903           Verify that API response for M1 is correct\n",
      "730            Verify that user is able to create claims\n",
      "891                  Verify that new shipment is created\n",
      "                             ...                        \n",
      "954                 Verify existing user re registration\n",
      "819                Verify the system settings parameters\n",
      "141            Verify the reports generated in dashboard\n",
      "769                         Verify new user registration\n",
      "954                 Verify existing user re registration\n",
      "Name: Test Case Title , Length: 339, dtype: category\n",
      "Categories (46, object): ['Test addition of new customisation for each p..., 'Test customisation portal', 'Test different methods of routing', 'Test email functionality', ..., 'Verify the reports generated in dashboard', 'Verify the system settings parameters', 'Verify update flag is modified when policy is..., 'Verify user is able to create new life insura...]\n",
      "\n",
      "Accuracy: 0.80\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from evalml.model_understanding.graphs import confusion_matrix\n",
    "import pickle\n",
    "\n",
    "\n",
    "best_pipeline = automl.best_pipeline\n",
    "automl.describe_pipeline(automl.rankings.iloc[0][\"id\"])\n",
    "\n",
    "# scores = best_pipeline.score(X_holdout, y_holdout,  objectives=evalml.objectives.get_core_objectives('multiclass'))\n",
    "scores = best_pipeline.score(X_train, y_train,  objectives=evalml.objectives.get_core_objectives('multiclass'))\n",
    "\n",
    "\n",
    "print(f'Accuracy Binary: {scores[\"Accuracy Multiclass\"]}')\n",
    "\n",
    "y_pred = best_pipeline.predict(X_train)\n",
    "print('Prdiction is',y_pred)\n",
    "mat=confusion_matrix(y_train, y_pred)\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "print('\\nAccuracy: {:.2f}\\n'.format(accuracy_score(y_train, y_pred)))\n",
    "\n",
    "\n",
    "\n",
    "with open(\"pipeline.pkl\", 'wb') as f:\n",
    "    pickle.dump(best_pipeline, f)\n",
    "\n",
    "# pickled_pipeline = None\n",
    "# with open('pipeline.pkl', 'rb') as f:\n",
    "#     pickled_pipeline= pickle.load(f)\n",
    "\n",
    "# assert pickled_pipeline == best_pipeline\n",
    "# pickled_pipeline.fit(X_holdout, y_train)\n",
    "\n",
    "\n",
    "# y1_pred=pickled_pipeline.predict(X_holdout)\n",
    "# print(y1_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ab383e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id                                      pipeline_name  search_order  \\\n",
      "0   4  LightGBM Classifier w/ Label Encoder + Imputer...             4   \n",
      "1   7  Decision Tree Classifier w/ Label Encoder + Im...             7   \n",
      "2   3  XGBoost Classifier w/ Label Encoder + Imputer ...             3   \n",
      "3   6  Random Forest Classifier w/ Label Encoder + Im...             6   \n",
      "4   8  Extra Trees Classifier w/ Label Encoder + Impu...             8   \n",
      "5   2  Logistic Regression Classifier w/ Label Encode...             2   \n",
      "6   1  Elastic Net Classifier w/ Label Encoder + Impu...             1   \n",
      "7   5  CatBoost Classifier w/ Label Encoder + Imputer...             5   \n",
      "8   0   Mode Baseline Multiclass Classification Pipeline             0   \n",
      "\n",
      "   mean_cv_score  standard_deviation_cv_score  validation_score  \\\n",
      "0       0.473431                     0.001468          0.474279   \n",
      "1       0.614929                     0.001483          0.615785   \n",
      "2       0.707476                     0.000815          0.707946   \n",
      "3       0.757882                     0.030713          0.744051   \n",
      "4       0.766581                     0.029969          0.749279   \n",
      "5       0.860137                     0.009236          0.865470   \n",
      "6       0.882878                     0.010130          0.888721   \n",
      "7       4.012056                     0.016987          3.993304   \n",
      "8      32.399206                     0.000000         32.399206   \n",
      "\n",
      "   percent_better_than_baseline  high_variance_cv  \\\n",
      "0                     98.538757             False   \n",
      "1                     98.102026             False   \n",
      "2                     97.816379             False   \n",
      "3                     97.660800             False   \n",
      "4                     97.633951             False   \n",
      "5                     97.345191             False   \n",
      "6                     97.275002             False   \n",
      "7                     87.616807             False   \n",
      "8                      0.000000             False   \n",
      "\n",
      "                                          parameters  \n",
      "0  {'Label Encoder': {'positive_label': None}, 'I...  \n",
      "1  {'Label Encoder': {'positive_label': None}, 'I...  \n",
      "2  {'Label Encoder': {'positive_label': None}, 'I...  \n",
      "3  {'Label Encoder': {'positive_label': None}, 'I...  \n",
      "4  {'Label Encoder': {'positive_label': None}, 'I...  \n",
      "5  {'Label Encoder': {'positive_label': None}, 'I...  \n",
      "6  {'Label Encoder': {'positive_label': None}, 'I...  \n",
      "7  {'Label Encoder': {'positive_label': None}, 'I...  \n",
      "8  {'Label Encoder': {'positive_label': None}, 'B...  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(automl.rankings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ad70bb1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test Case Title</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>654</th>\n",
       "      <td>New Hire - Key Fields Will Need to be Entered ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>29a - Downgrade With Paychange (EC does not re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>903</th>\n",
       "      <td>Verify new data and term addition details</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>Verify that requsition email is generated corr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>Verify that requsition email is generated corr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1201</th>\n",
       "      <td>Delivered Corrupted file- ECPth_CybershiftElem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1479</th>\n",
       "      <td>Delivered Corrupted file- ECPth_CybershiftElem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1122</th>\n",
       "      <td>SIT2-EC-OB-Aztek-Employee Status: Displaying s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044</th>\n",
       "      <td>SIT2-EC-OB-Aztek-Employee Status: Displaying s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1377</th>\n",
       "      <td>Amex Concur File - For fields -350_custom5 &amp; 3...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1500 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Test Case Title \n",
       "ID                                                     \n",
       "654   New Hire - Key Fields Will Need to be Entered ...\n",
       "53    29a - Downgrade With Paychange (EC does not re...\n",
       "903           Verify new data and term addition details\n",
       "730   Verify that requsition email is generated corr...\n",
       "891   Verify that requsition email is generated corr...\n",
       "...                                                 ...\n",
       "1201  Delivered Corrupted file- ECPth_CybershiftElem...\n",
       "1479  Delivered Corrupted file- ECPth_CybershiftElem...\n",
       "1122  SIT2-EC-OB-Aztek-Employee Status: Displaying s...\n",
       "1044  SIT2-EC-OB-Aztek-Employee Status: Displaying s...\n",
       "1377  Amex Concur File - For fields -350_custom5 & 3...\n",
       "\n",
       "[1500 rows x 1 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = pd.DataFrame(y_pred)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "40df8f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output.to_excel('output1.xlsx', engine='xlsxwriter')\n",
    "output.to_csv('output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "db9918e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_read = pd.read_csv('output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "d145737f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Corpus created successfully**\n",
      "**Dimension for Text features are (1219, 115)**\n",
      "**Dimension for features data frame are (1219, 125)**\n",
      "X_test\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>115</th>\n",
       "      <th>116</th>\n",
       "      <th>117</th>\n",
       "      <th>118</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>399</td>\n",
       "      <td>7928</td>\n",
       "      <td>6.3</td>\n",
       "      <td>P1</td>\n",
       "      <td>0</td>\n",
       "      <td>High</td>\n",
       "      <td>No</td>\n",
       "      <td>IAM</td>\n",
       "      <td>No</td>\n",
       "      <td>Script IAM59</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>364</td>\n",
       "      <td>7893</td>\n",
       "      <td>5.3.2</td>\n",
       "      <td>P4</td>\n",
       "      <td>0</td>\n",
       "      <td>High</td>\n",
       "      <td>No</td>\n",
       "      <td>ABX</td>\n",
       "      <td>yes</td>\n",
       "      <td>Script ABX44</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1051</th>\n",
       "      <td>1051</td>\n",
       "      <td>8008</td>\n",
       "      <td>2.5</td>\n",
       "      <td>P2</td>\n",
       "      <td>0</td>\n",
       "      <td>High</td>\n",
       "      <td>Yes</td>\n",
       "      <td>TENY</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Script TENY113</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>519</td>\n",
       "      <td>8062</td>\n",
       "      <td>6.3</td>\n",
       "      <td>P1</td>\n",
       "      <td>0</td>\n",
       "      <td>High</td>\n",
       "      <td>No</td>\n",
       "      <td>PRF</td>\n",
       "      <td>No</td>\n",
       "      <td>Manual Testing</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>789</th>\n",
       "      <td>789</td>\n",
       "      <td>7505</td>\n",
       "      <td>3.2</td>\n",
       "      <td>P0</td>\n",
       "      <td>1</td>\n",
       "      <td>High</td>\n",
       "      <td>No</td>\n",
       "      <td>ABX</td>\n",
       "      <td>yes</td>\n",
       "      <td>Script ABX02</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>666</td>\n",
       "      <td>7649</td>\n",
       "      <td>8.2</td>\n",
       "      <td>P3</td>\n",
       "      <td>0</td>\n",
       "      <td>Low</td>\n",
       "      <td>No</td>\n",
       "      <td>PRF</td>\n",
       "      <td>No</td>\n",
       "      <td>Script PRF26</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>229</td>\n",
       "      <td>7866</td>\n",
       "      <td>1.0.3</td>\n",
       "      <td>P1</td>\n",
       "      <td>2</td>\n",
       "      <td>High</td>\n",
       "      <td>No</td>\n",
       "      <td>IAM</td>\n",
       "      <td>No</td>\n",
       "      <td>Script IAM59</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>737</td>\n",
       "      <td>7620</td>\n",
       "      <td>6.3</td>\n",
       "      <td>P2</td>\n",
       "      <td>0</td>\n",
       "      <td>Medium</td>\n",
       "      <td>No</td>\n",
       "      <td>IAM</td>\n",
       "      <td>No</td>\n",
       "      <td>Script IAM12</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1123</th>\n",
       "      <td>1123</td>\n",
       "      <td>8138</td>\n",
       "      <td>6.3</td>\n",
       "      <td>P2</td>\n",
       "      <td>0</td>\n",
       "      <td>High</td>\n",
       "      <td>No</td>\n",
       "      <td>PRF</td>\n",
       "      <td>No</td>\n",
       "      <td>Script PFR94</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>506</td>\n",
       "      <td>8049</td>\n",
       "      <td>4.1</td>\n",
       "      <td>P1</td>\n",
       "      <td>0</td>\n",
       "      <td>Medium</td>\n",
       "      <td>No</td>\n",
       "      <td>TENY</td>\n",
       "      <td>No</td>\n",
       "      <td>Manual Testing</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>244 rows × 125 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0     1      2   3   4       5    6     7    8               9    ...  \\\n",
       "399    399  7928    6.3  P1   0    High   No   IAM   No    Script IAM59  ...   \n",
       "364    364  7893  5.3.2  P4   0    High   No   ABX  yes    Script ABX44  ...   \n",
       "1051  1051  8008    2.5  P2   0    High  Yes  TENY  Yes  Script TENY113  ...   \n",
       "519    519  8062    6.3  P1   0    High   No   PRF   No  Manual Testing  ...   \n",
       "789    789  7505    3.2  P0   1    High   No   ABX  yes    Script ABX02  ...   \n",
       "...    ...   ...    ...  ..  ..     ...  ...   ...  ...             ...  ...   \n",
       "666    666  7649    8.2  P3   0     Low   No   PRF   No    Script PRF26  ...   \n",
       "229    229  7866  1.0.3  P1   2    High   No   IAM   No    Script IAM59  ...   \n",
       "737    737  7620    6.3  P2   0  Medium   No   IAM   No    Script IAM12  ...   \n",
       "1123  1123  8138    6.3  P2   0    High   No   PRF   No    Script PFR94  ...   \n",
       "506    506  8049    4.1  P1   0  Medium   No  TENY   No  Manual Testing  ...   \n",
       "\n",
       "     115 116 117 118 119 120 121 122 123 124  \n",
       "399    0   0   0   0   0   0   1   0   1   0  \n",
       "364    0   0   0   0   0   0   2   0   0   0  \n",
       "1051   0   0   0   0   0   0   1   0   1   0  \n",
       "519    0   0   0   0   0   0   2   0   0   0  \n",
       "789    0   0   0   0   0   0   1   0   0   0  \n",
       "...   ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  \n",
       "666    0   0   0   0   0   0   1   0   0   0  \n",
       "229    0   0   2   0   0   0   0   0   0   0  \n",
       "737    1   1   0   0   0   0   1   0   0   0  \n",
       "1123   0   0   0   0   0   0   1   0   0   0  \n",
       "506    0   0   0   0   0   0   2   0   0   0  \n",
       "\n",
       "[244 rows x 125 columns]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# import plotly.graph_objects as go\n",
    "# import plotly.express as px\n",
    "\n",
    "# Creating function to print in bold\n",
    "# from IPython.display import Markdown, display\n",
    "\n",
    "# print(\"hello\")\n",
    "# dataset = pd.read_excel('TestData _MasterInput_0.4.xlsx')\n",
    "dataset = pd.read_excel('Dummy Dataset0.3.xlsx')\n",
    "final = dataset\n",
    "# print(dataset)\n",
    "# print(dataset['Release ID'].unique())\n",
    "# print(dataset['Release ID'].value_counts())\n",
    "# print(dataset.columns)\n",
    "\n",
    "# one_hot_encoded_data = pd.get_dummies(dataset, columns = ['Release ID', 'Test Case Priority'])\n",
    "# print(one_hot_encoded_data)\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "labelencoder = LabelEncoder()\n",
    "# dataset['Release ID'] = labelencoder.fit_transform(dataset['Release ID'].astype(str))\n",
    "#dataset['ID'] = labelencoder.fit_transform(dataset['ID'])\n",
    "# dataset['TestCase Priority'] = labelencoder.fit_transform(dataset['TestCase Priority'])\n",
    "# a  = labelencoder.inverse_transform(dataset['TestCase Priority'])\n",
    "# dataset['Severity of Defects'] = labelencoder.fit_transform(dataset['Severity of Defects'])\n",
    "# dataset['Error Prone Test case'] = labelencoder.fit_transform(dataset['Error Prone Test case'])\n",
    "# dataset['Automation Status'] = labelencoder.fit_transform(dataset['Automation Status'])\n",
    "# dataset['Linked Defects'] = labelencoder.fit_transform(dataset['Linked Defects'])\n",
    "# dataset['Module'] = labelencoder.fit_transform(dataset['Module'])\n",
    "# dataset['Automation script'] = labelencoder.fit_transform(dataset['Automation script'])\n",
    "\n",
    "# dataset['Test Case Title']=labelencoder.fit_transform(dataset['Test Case Title'])\n",
    "dataset.head()\n",
    "dataset.reset_index(inplace=True)\n",
    "#print(dataset.to_string())\n",
    "#print(dataset.head().to_string())\n",
    "#print(dataset.value_counts())\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "corpus_title = []\n",
    "pstem = PorterStemmer()\n",
    "for i in range(dataset['Test Case Title'].shape[0]):\n",
    "    # Remove unwanted words\n",
    "    text = re.sub(\"[^a-zA-Z]\", ' ', dataset['Test Case Title'][i])\n",
    "    # Transform words to lowercase\n",
    "    text = text.lower()\n",
    "    text = text.split()\n",
    "    # Remove stopwords then Stemming it\n",
    "    text = [pstem.stem(word) for word in text if not word in set(stopwords.words('english'))]\n",
    "    text = ' '.join(text)\n",
    "    # Append cleaned tweet to corpus\n",
    "    corpus_title.append(text)\n",
    "\n",
    "print(\"**Corpus created successfully**\")\n",
    "\n",
    "# Creating the Bag of Words model\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer()\n",
    "text_vectors= cv.fit_transform(corpus_title).toarray()\n",
    "\n",
    "#Convert text vectors into data frame\n",
    "text_vectors_df=pd.DataFrame(text_vectors)\n",
    "print(\"**Dimension for Text features are {}**\".format(text_vectors_df.shape))\n",
    "\n",
    "#Getting Target variable into Y variable\n",
    "y=dataset[['Target']].values\n",
    "#Converting 2 dimensional y and y_pred array into single dimension\n",
    "y=y.ravel()\n",
    "\n",
    "#Removing 'Target' and 'TestCaseTitle' columns from actual dataset\n",
    "dataset=dataset.drop(['Target','Test Case Title'],axis=1)\n",
    "\n",
    "#Creating new data frame with all categorical feature and Text features for training classifier models\n",
    "X=pd.concat([dataset,text_vectors_df],axis=1).values\n",
    "print(\"**Dimension for features data frame are {}**\".format(X.shape))\n",
    "#X.head()\n",
    "\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)\n",
    "X_train, X_test, y_train, y_test = evalml.preprocessing.split_data(X, y, problem_type='binary', test_size=0.2, random_seed=0)\n",
    "final_data = X_test\n",
    "print(\"X_test\")\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "b2179046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing columns [0, 1] because they are of 'Unknown' type\n",
      "Generating pipelines to search over...\n",
      "1 pipelines ready for search.\n",
      "\n",
      "*****************************\n",
      "* Beginning pipeline search *\n",
      "*****************************\n",
      "\n",
      "Optimizing for Log Loss Binary. \n",
      "Lower score is better.\n",
      "\n",
      "Using SequentialEngine to train and score pipelines.\n",
      "Searching up to 1 batches for a total of 2 pipelines. \n",
      "Allowed model families: xgboost\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a47690870ae547df88583ee4ea0d1ffa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'mode': 'lines+markers',\n",
       "              'name': 'Best Score',\n",
       "              'type'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Baseline Pipeline: Mode Baseline Binary Classification Pipeline\n",
      "Mode Baseline Binary Classification Pipeline:\n",
      "\tStarting cross validation\n",
      "\tFinished cross validation - mean Log Loss Binary: 13.072\n",
      "\n",
      "*****************************\n",
      "* Evaluating Batch Number 1 *\n",
      "*****************************\n",
      "\n",
      "XGBoost Classifier w/ Label Encoder + Drop Columns Transformer + Imputer + One Hot Encoder:\n",
      "\tStarting cross validation\n",
      "\tFinished cross validation - mean Log Loss Binary: 0.159\n",
      "\n",
      "Search finished after 00:18            \n",
      "Best pipeline: XGBoost Classifier w/ Label Encoder + Drop Columns Transformer + Imputer + One Hot Encoder\n",
      "Best pipeline Log Loss Binary: 0.158630\n",
      "\n",
      "**********************************************************************************************\n",
      "* XGBoost Classifier w/ Label Encoder + Drop Columns Transformer + Imputer + One Hot Encoder *\n",
      "**********************************************************************************************\n",
      "\n",
      "Problem Type: binary\n",
      "Model Family: XGBoost\n",
      "\n",
      "Pipeline Steps\n",
      "==============\n",
      "1. Label Encoder\n",
      "\t * positive_label : None\n",
      "2. Drop Columns Transformer\n",
      "\t * columns : [0, 1]\n",
      "3. Imputer\n",
      "\t * categorical_impute_strategy : most_frequent\n",
      "\t * numeric_impute_strategy : mean\n",
      "\t * categorical_fill_value : None\n",
      "\t * numeric_fill_value : None\n",
      "4. One Hot Encoder\n",
      "\t * top_n : 10\n",
      "\t * features_to_encode : None\n",
      "\t * categories : None\n",
      "\t * drop : if_binary\n",
      "\t * handle_unknown : ignore\n",
      "\t * handle_missing : error\n",
      "5. XGBoost Classifier\n",
      "\t * eta : 0.1\n",
      "\t * max_depth : 6\n",
      "\t * min_child_weight : 1\n",
      "\t * n_estimators : 100\n",
      "\t * n_jobs : -1\n",
      "\t * eval_metric : logloss\n",
      "\n",
      "Training\n",
      "========\n",
      "Training for binary problems.\n",
      "Total training time (including CV): 15.5 seconds\n",
      "\n",
      "Cross Validation\n",
      "----------------\n",
      "             Log Loss Binary  MCC Binary  Gini   AUC  Precision    F1  Balanced Accuracy Binary  Accuracy Binary # Training # Validation\n",
      "0                      0.094       0.901 0.991 0.995      0.891 0.938                     0.959            0.951        650          325\n",
      "1                      0.132       0.889 0.977 0.988      0.927 0.931                     0.945            0.948        650          325\n",
      "2                      0.250       0.849 0.935 0.968      0.931 0.904                     0.919            0.929        650          325\n",
      "mean                   0.159       0.880 0.968 0.984      0.916 0.924                     0.941            0.943          -            -\n",
      "std                    0.081       0.027 0.029 0.015      0.022 0.018                     0.020            0.012          -            -\n",
      "coef of var            0.510       0.031 0.030 0.015      0.024 0.020                     0.021            0.012          -            -\n",
      "Accuracy Binary: 0.9795081967213115\n",
      "Prdiction is 399     0\n",
      "364     0\n",
      "1051    0\n",
      "519     0\n",
      "789     1\n",
      "       ..\n",
      "666     0\n",
      "229     1\n",
      "737     0\n",
      "1123    0\n",
      "506     0\n",
      "Name: 1, Length: 244, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# EvalMl code\n",
    "import evalml\n",
    "automl = evalml.automl.AutoMLSearch(X_train=X_train, y_train=y_train, problem_type='binary',verbose=True,\n",
    "                                    max_batches=1,\n",
    "                                    allowed_model_families=[\"XGBOOST\"])\n",
    "automl.search()\n",
    "\n",
    "from evalml.model_understanding.graphs import confusion_matrix\n",
    "import pickle\n",
    "\n",
    "\n",
    "best_pipeline = automl.best_pipeline\n",
    "automl.describe_pipeline(automl.rankings.iloc[0][\"id\"])\n",
    "\n",
    "# scores = best_pipeline.score(X_holdout, y_holdout,  objectives=evalml.objectives.get_core_objectives('multiclass'))\n",
    "scores = best_pipeline.score(X_test, y_test,  objectives=evalml.objectives.get_core_objectives('binary'))\n",
    "\n",
    "\n",
    "print(f'Accuracy Binary: {scores[\"Accuracy Binary\"]}')\n",
    "\n",
    "y_pred = best_pipeline.predict(X_test)\n",
    "print('Prdiction is',y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "5cdd90a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prdiction is 0       1\n",
      "1       1\n",
      "2       1\n",
      "3       1\n",
      "4       1\n",
      "       ..\n",
      "1214    0\n",
      "1215    0\n",
      "1216    0\n",
      "1217    0\n",
      "1218    0\n",
      "Name: 1, Length: 1219, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "y_pred = best_pipeline.predict(X)\n",
    "print('Prdiction is',y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "275574a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Modules</th>\n",
       "      <th>Scripts</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7500</td>\n",
       "      <td>ABX</td>\n",
       "      <td>Script ABX01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7501</td>\n",
       "      <td>PRF</td>\n",
       "      <td>Script PRF27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7502</td>\n",
       "      <td>IAM</td>\n",
       "      <td>Script IAM12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7503</td>\n",
       "      <td>PRF</td>\n",
       "      <td>Manual Testing</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7504</td>\n",
       "      <td>CFE</td>\n",
       "      <td>Manual Testing</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1104</th>\n",
       "      <td>8159</td>\n",
       "      <td>CFE</td>\n",
       "      <td>Script CFE54</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1105</th>\n",
       "      <td>8160</td>\n",
       "      <td>TNT</td>\n",
       "      <td>Script TNT120</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1106</th>\n",
       "      <td>8161</td>\n",
       "      <td>ABX</td>\n",
       "      <td>Script ABX41</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1107</th>\n",
       "      <td>8162</td>\n",
       "      <td>CFE</td>\n",
       "      <td>Script CFE50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1108</th>\n",
       "      <td>8163</td>\n",
       "      <td>TNT</td>\n",
       "      <td>Script TNT116</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>330 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID Modules         Scripts  Target\n",
       "0     7500     ABX    Script ABX01       1\n",
       "1     7501     PRF    Script PRF27       1\n",
       "2     7502     IAM    Script IAM12       1\n",
       "3     7503     PRF  Manual Testing       1\n",
       "4     7504     CFE  Manual Testing       1\n",
       "...    ...     ...             ...     ...\n",
       "1104  8159     CFE    Script CFE54       0\n",
       "1105  8160     TNT   Script TNT120       0\n",
       "1106  8161     ABX    Script ABX41       1\n",
       "1107  8162     CFE    Script CFE50       1\n",
       "1108  8163     TNT   Script TNT116       1\n",
       "\n",
       "[330 rows x 4 columns]"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset1 = pd.read_excel('TestData _MasterInput_0.4.xlsx')\n",
    "output = pd.DataFrame(y_pred)#,columns=['Target'])\n",
    "output.rename(columns={1:'Target'},inplace=True)\n",
    "# output = pd.concat([dataset1[dataset1.ID.isin(pd.DataFrame(X_test)[1])], output], axis=1)\n",
    "output = pd.concat([pd.DataFrame(X)[[1,7,9]],output], axis=1)\n",
    "\n",
    "# output = pd.concat([(pd.DataFrame(X_test)[1]), output], axis=1)\n",
    "output.dropna(inplace=True)\n",
    "output.drop_duplicates(subset=[1], inplace=True)\n",
    "output.rename(columns={1:'ID',7:\"Modules\",9:\"Scripts\",'Target':\"Target\"},inplace=True)\n",
    "# output.to_csv('output.csv')#,columns=['ID', 'Target'])\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "67567bfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    524\n",
       "dtype: int64"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(pd.DataFrame(X_test)[1].unique()).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "75bf2b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1 = pd.read_excel('TestData _MasterInput_0.4.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3f1208ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Release ID</th>\n",
       "      <th>Test Case Title</th>\n",
       "      <th>TestCase Priority</th>\n",
       "      <th>Linked Defects</th>\n",
       "      <th>Severity of Defects</th>\n",
       "      <th>Error Prone Test case</th>\n",
       "      <th>Module</th>\n",
       "      <th>Automation Status</th>\n",
       "      <th>Automation script</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>8.2</td>\n",
       "      <td>Verify that functionlity A is working as expec...</td>\n",
       "      <td>P1</td>\n",
       "      <td>2</td>\n",
       "      <td>High</td>\n",
       "      <td>Yes</td>\n",
       "      <td>ABX</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Script ABX01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>8.2</td>\n",
       "      <td>Verify that user is able to login to the portal</td>\n",
       "      <td>P3</td>\n",
       "      <td>1</td>\n",
       "      <td>Medium</td>\n",
       "      <td>No</td>\n",
       "      <td>PRF</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Script PRF27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>8.2</td>\n",
       "      <td>Verify that API response for M1 is correct</td>\n",
       "      <td>P2</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>Yes</td>\n",
       "      <td>IAM</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Script IAM12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>8.2</td>\n",
       "      <td>Verify that user is able to create claims</td>\n",
       "      <td>P1</td>\n",
       "      <td>0</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Yes</td>\n",
       "      <td>PRF</td>\n",
       "      <td>No</td>\n",
       "      <td>Manual Testing</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>8.2</td>\n",
       "      <td>Verify that new shipment is created</td>\n",
       "      <td>P1</td>\n",
       "      <td>0</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Yes</td>\n",
       "      <td>CFE</td>\n",
       "      <td>No</td>\n",
       "      <td>Manual Testing</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3566</th>\n",
       "      <td>7826</td>\n",
       "      <td>5.3.2</td>\n",
       "      <td>Informations Emploi-cas121-11401656</td>\n",
       "      <td>P0</td>\n",
       "      <td>2</td>\n",
       "      <td>High</td>\n",
       "      <td>No</td>\n",
       "      <td>IAM</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Script 1573</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3567</th>\n",
       "      <td>7827</td>\n",
       "      <td>5.3.2</td>\n",
       "      <td>Informations Emploi-cas122-11407999</td>\n",
       "      <td>P3</td>\n",
       "      <td>4</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Yes</td>\n",
       "      <td>IAM</td>\n",
       "      <td>No</td>\n",
       "      <td>Manual Testing</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3568</th>\n",
       "      <td>7828</td>\n",
       "      <td>5.3.2</td>\n",
       "      <td>Informations Emploi-cas123-11409075</td>\n",
       "      <td>P2</td>\n",
       "      <td>3</td>\n",
       "      <td>High</td>\n",
       "      <td>Yes</td>\n",
       "      <td>INRA</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Script 1374</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3569</th>\n",
       "      <td>7829</td>\n",
       "      <td>5.3.2</td>\n",
       "      <td>Informations Emploi-cas124-11407276</td>\n",
       "      <td>P0</td>\n",
       "      <td>4</td>\n",
       "      <td>High</td>\n",
       "      <td>No</td>\n",
       "      <td>PRF</td>\n",
       "      <td>No</td>\n",
       "      <td>Manual Testing</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3570</th>\n",
       "      <td>7830</td>\n",
       "      <td>5.3.2</td>\n",
       "      <td>Informations Emploi-cas125-11402470</td>\n",
       "      <td>P1</td>\n",
       "      <td>2</td>\n",
       "      <td>Low</td>\n",
       "      <td>No</td>\n",
       "      <td>TENY</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Script 1273</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3571 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID Release ID                                    Test Case Title  \\\n",
       "0        1        8.2  Verify that functionlity A is working as expec...   \n",
       "1        2        8.2    Verify that user is able to login to the portal   \n",
       "2        3        8.2         Verify that API response for M1 is correct   \n",
       "3        4        8.2          Verify that user is able to create claims   \n",
       "4        5        8.2                Verify that new shipment is created   \n",
       "...    ...        ...                                                ...   \n",
       "3566  7826      5.3.2                Informations Emploi-cas121-11401656   \n",
       "3567  7827      5.3.2                Informations Emploi-cas122-11407999   \n",
       "3568  7828      5.3.2                Informations Emploi-cas123-11409075   \n",
       "3569  7829      5.3.2                Informations Emploi-cas124-11407276   \n",
       "3570  7830      5.3.2                Informations Emploi-cas125-11402470   \n",
       "\n",
       "     TestCase Priority  Linked Defects Severity of Defects  \\\n",
       "0                   P1               2                High   \n",
       "1                   P3               1              Medium   \n",
       "2                   P2               1                 Low   \n",
       "3                   P1               0              Medium   \n",
       "4                   P1               0              Medium   \n",
       "...                ...             ...                 ...   \n",
       "3566                P0               2                High   \n",
       "3567                P3               4              Medium   \n",
       "3568                P2               3                High   \n",
       "3569                P0               4                High   \n",
       "3570                P1               2                 Low   \n",
       "\n",
       "     Error Prone Test case Module Automation Status Automation script  Target  \n",
       "0                      Yes    ABX               Yes      Script ABX01       1  \n",
       "1                       No    PRF               Yes      Script PRF27       1  \n",
       "2                      Yes    IAM               Yes      Script IAM12       1  \n",
       "3                      Yes    PRF                No    Manual Testing       0  \n",
       "4                      Yes    CFE                No    Manual Testing       1  \n",
       "...                    ...    ...               ...               ...     ...  \n",
       "3566                    No    IAM               Yes       Script 1573       0  \n",
       "3567                   Yes    IAM                No    Manual Testing       0  \n",
       "3568                   Yes   INRA               Yes       Script 1374       0  \n",
       "3569                    No    PRF                No    Manual Testing       0  \n",
       "3570                    No   TENY               Yes       Script 1273       0  \n",
       "\n",
       "[3571 rows x 11 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "65bc45f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(X_test).to_excel(\"x_test.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "752ed86c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>7</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>396</td>\n",
       "      <td>IAM</td>\n",
       "      <td>Manual Testing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4566</td>\n",
       "      <td>IAM</td>\n",
       "      <td>Script 1127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4077</td>\n",
       "      <td>TENY</td>\n",
       "      <td>Script 671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>118</td>\n",
       "      <td>MIGRA</td>\n",
       "      <td>Script MIGRA24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4053</td>\n",
       "      <td>CFE</td>\n",
       "      <td>Script 649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>4556</td>\n",
       "      <td>TENY</td>\n",
       "      <td>Manual Testing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>3</td>\n",
       "      <td>IAM</td>\n",
       "      <td>Script IAM12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>4192</td>\n",
       "      <td>MIGRA</td>\n",
       "      <td>Manual Testing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>713</th>\n",
       "      <td>71</td>\n",
       "      <td>PRF</td>\n",
       "      <td>Manual Testing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714</th>\n",
       "      <td>7501</td>\n",
       "      <td>INRA</td>\n",
       "      <td>Script 1256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>715 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        1      7               9\n",
       "0     396    IAM  Manual Testing\n",
       "1    4566    IAM     Script 1127\n",
       "2    4077   TENY      Script 671\n",
       "3     118  MIGRA  Script MIGRA24\n",
       "4    4053    CFE      Script 649\n",
       "..    ...    ...             ...\n",
       "710  4556   TENY  Manual Testing\n",
       "711     3    IAM    Script IAM12\n",
       "712  4192  MIGRA  Manual Testing\n",
       "713    71    PRF  Manual Testing\n",
       "714  7501   INRA     Script 1256\n",
       "\n",
       "[715 rows x 3 columns]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pd.concat(pd.DataFrame(X_test)[9],pd.DataFrame(X_test)[7],pd.DataFrame(X_test)[1])\n",
    "pd.DataFrame(X_test)[[1,7,9]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "d218f7be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       ID Modules         Scripts\n",
      "0     396     IAM  Manual Testing\n",
      "1    4566     IAM     Script 1127\n",
      "2    4077    TENY      Script 671\n",
      "3     118   MIGRA  Script MIGRA24\n",
      "4    4053     CFE      Script 649\n",
      "..    ...     ...             ...\n",
      "706  4367   MIGRA      Script 939\n",
      "707  4408     CFE      Script 979\n",
      "708  4449    TENY     Script 1016\n",
      "710  4556    TENY  Manual Testing\n",
      "713    71     PRF  Manual Testing\n",
      "\n",
      "[524 rows x 3 columns]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'writer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8492/4178160049.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mall_info_tc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaster_dataframe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m pd.DataFrame(master_dataframe.iloc[:,0:2], columns=[\"Test ID\", 'Module', \"Automation Script Name\"]).to_excel(writer,\n\u001b[0m\u001b[0;32m      6\u001b[0m                                                                                   \u001b[0msheet_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Master_Output\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m                                                                                   index=False)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'writer' is not defined"
     ]
    }
   ],
   "source": [
    "master_dataframe = output\n",
    "all_tc = []\n",
    "all_info_tc = []\n",
    "print(master_dataframe.iloc[:,0:3])\n",
    "pd.DataFrame(master_dataframe.iloc[:,0:2], columns=[\"Test ID\", 'Module', \"Automation Script Name\"]).to_excel(writer,\n",
    "                                                                                  sheet_name=\"Master_Output\",\n",
    "                                                                                  index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "b1053c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_dataframe.iloc[0,2]\n",
    "df = master_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "664e8280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = master_dataframe\n",
    "m_tc = []\n",
    "a_tc = []\n",
    "# if limit == 0:\n",
    "for i in range(len(df.iloc[:,0])):\n",
    "    if df.iloc[i,2] == \"Manual Testing\":\n",
    "        m_tc.append((df.iloc[i,0], df.iloc[i,1], df.iloc[i,2]))\n",
    "    else:\n",
    "        a_tc.append((df.iloc[i,1], df.iloc[i,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "76c5e183",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      Manual Testing\n",
       "1         Script 1127\n",
       "2          Script 671\n",
       "3      Script MIGRA24\n",
       "4          Script 649\n",
       "            ...      \n",
       "706        Script 939\n",
       "707        Script 979\n",
       "708       Script 1016\n",
       "710    Manual Testing\n",
       "713    Manual Testing\n",
       "Name: Scripts, Length: 524, dtype: object"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "9e1cee0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# master_dataframe.set_index('ID').join(final.set_index('ID'), on='ID')\n",
    "# master_dataframe.ID\n",
    "master_dataframe = master_dataframe.astype({\"ID\": int})\n",
    "# master_dataframe.dtypes\n",
    "# master_dataframe.set_index('ID').join(final.set_index('ID'))\n",
    "\n",
    "master_dataframe = pd.merge(left=final[['ID', 'Test Case Title']], right=master_dataframe, how='right', left_on='ID', right_on='ID')\n",
    "# merged_left\n",
    "# final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "f321daf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Manual List----------\n",
      "[(8062, 'Verify Granular Scope: Verify granular scope assigned for Scope Reduction Token Exchange grant type', 'PRF'), (8059, 'Verify Granular Scope: Verify non assigned scopes for Client credential grant type', 'PRF'), (8031, 'Create access and refresh token using invalid auth code', 'IAM'), (8045, 'Verify Introspect Token API : Verify token exchange grant type access token', 'CFE'), (7900, 'Verify Granular Scope: Verify granular scope assigned for Printer JWE Token Exchange grant type', 'CFE'), (7608, 'Verify Create client API with invalid grant types scope parameter', 'TNT'), (8057, 'Verify Granular Scope : Verify scopes for authorization grant type', 'CFE'), (7535, 'Create access and refresh tokens using invalid grant type', 'PRF'), (7901, 'Verify Granular Scope: Verify non assigned scopes for Printer JWE Toke Exchange grant type', 'INRA'), (8041, 'Verify token exchange API for missing attribute', 'IAM'), (7984, 'Verify Client On boarding for App type as Native with Privileged Client', 'ABX'), (8056, 'Verify Granular Scope : Verify granular scope assigned for authorization grant type', 'TNT'), (7545, 'Verify Introspect Token API : Verify Client Credential grant type access token', 'CFE'), (7931, 'Verify Create client API with unsupported grant type parameter', 'TENY'), (7531, 'Verify Entity token with missing grant type', 'ABX'), (8054, 'Verify Scope Reduction API : Verify scope reduction API for invalid subject token type', 'ABX'), (8047, 'Verify Introspect Token API : Verify Client Credential grant type access token with invalid token type hint', 'PRF'), (8033, 'Create access and refresh tokens using invalid grant type', 'PRF'), (7930, 'Verify Create client API with unsupported application type parameter', 'ABX'), (7983, 'Verify Client On boarding for App type as Native with Default Client', 'TNT'), (7915, 'Verify User Delegation API without optional parameter scopes', 'PRF'), (7513, 'Verify Token API for Client Credentials grant type : Verify token API for invalid scopes', 'CFE'), (7552, 'Verify Scope Reduction API : Exchange Access token with reduced scopes token', 'TNT'), (7520, 'Verify Token API for refresh token grant type : Verify refresh token API with invalid refresh token', 'PRF'), (7905, 'Verify User Delegation token generation for scope reduction grant type token', 'ABX'), (8063, 'Verify Granular Scope: Verify non assigned scopes for Scope Reduction Toke Exchange grant type', 'IAM'), (7605, 'Verify Create client API without app type parameter', 'ABX'), (8043, 'Verify Introspect Token API : Verify Client Credential grant type access token', 'PRF'), (8051, 'Verify Scope Reduction API : Exchange Access token with same scopes token', 'INRA'), (7979, 'Verify Delete client API with invalid client id', 'TNT'), (8060, 'Verify Granular Scope: Verify granular scope assigned for Client Delegation Toke Exchange grant type', 'TNT'), (7906, 'Verify User Delegation token generation for client delegation grant type token', 'TENY'), (8074, 'Verify User Delegation token generation with requested user as WPID', 'TENY'), (8066, 'Verify Granular Scope: Verify granular scope assigned for Printer JWE Token Exchange grant type', 'CFE'), (8028, 'Verify Entity token with invalid client id', 'PRF'), (8053, 'Verify Scope Reduction API : Verify scope reduction API for invalid client', 'IAM'), (8048, 'Verify Introspect Token API : Verify introspect token API for invalid client credentials', 'ABX'), (8065, 'Verify Granular Scope: Verify non assigned scopes for ID Toke Exchange grant type', 'PRF'), (8023, 'Generate Entity token with empty scope in request payload', 'CFE'), (7528, 'Verify Entity token with invalid grant type type in request payload', 'INRA'), (7553, 'Verify Scope Reduction API : Exchange Access token with same scopes token', 'TNT'), (7536, 'Create access and refresh token using invalid auth', 'TNT'), (8058, 'Verify Granular Scope: Verify granular scope assigned for Client credential grant type', 'TNT'), (7518, 'Verify Token API for refresh token grant type : Verify refresh token API for missing grant type', 'ABX'), (8042, 'Verify token exchange API for invalid subject token', 'ABX'), (8022, 'Verify Entity token for invalid cloud id', 'CFE'), (8069, 'Verify Granular Scope: Verify granular scope not assigned for Refresh Token grant type', 'PRF'), (8070, 'Verify User Delegation token generation for token exchange grant type token', 'ABX'), (8029, 'Verify Entity token with missing grant type', 'INRA'), (7503, 'Verify Client delegation API: Exchange Access token of different client with different scope', 'PRF'), (7517, 'Verify Token API for refresh token grant type : Verify refresh token API for invalid grant type', 'PRF'), (8073, 'Verify User Delegation token generation with requested user as HPID', 'INRA'), (8040, 'Verify token exchange API for invalid grant type', 'PRF'), (8044, 'Verify Introspect Token API : Verify Client Credential grant type access token with valid token type hint', 'CFE'), (8011, 'Verify Token API for Client Credentials grant type : Verify token API for invalid scopes', 'PRF'), (7991, 'Verify Token generated with greater length in RP based service', 'PRF'), (8049, 'Verify Introspect Token API : Verify reduced scopes in introspect token API', 'TENY')]\n",
      "---------Auto List----------\n",
      "[('Verify Create client API without client name', 'IAM'), ('Verify Granular Scope: Verify non assigned scopes for Client credential grant type', 'ABX'), ('Verify Token API for Client Credentials grant type : Generate token without Scopes in request payload', 'TENY'), ('Verify Client delegation API:Exchange Access token of different client with on boarded client scopes with empty scopes in request payload', 'ABX'), ('Verify User Delegation API without mandatory parameter Requested User Type', 'IAM'), ('Verify Delete client API with Bearer token of unauthorized client', 'IAM'), ('Verify Update client API with client id issue id as future date', 'IAM'), ('Verify Refresh Token for Parallel Login : Verify Access token generation for used/leaked refresh token from a client which have max refresh token value as two', 'MIGRA'), ('Generate Entity token with valid request payload', 'IAM'), ('Verify Update client API with unsupported auth method parameter', 'ABX'), ('Get the AuthZ service metadata', 'INRA'), ('Verify Granular Scope: Verify non assigned scopes for Scope Reduction Toke Exchange grant type', 'CFE'), ('Verify Get client API with expired Bearer Token', 'TNT'), ('Verify Client delegation API : Verify client delegation API for invalid subject token', 'INRA'), ('Verify Client delegation API :Verify client delegation API for invalid grant type', 'TNT'), ('Verify Client On boarding for App type as Browser with Default Client', 'INRA'), ('Get client details for an on boarded client', 'TENY'), ('Verify Smart APP Flows for new HPID user : Sign Up Flow', 'INRA'), ('Verify Update client API without grant type parameter', 'PRF'), ('Verify Refresh Token for Parallel Login : Verify Access token generation for used/leaked refresh token from a client which have max refresh token value as two', 'MIGRA'), ('Verify Scope Reduction API : Exchange ID token Exchange type access token with reduced scopes token', 'PRF'), ('Verify Get client API with invalid client id', 'TNT'), ('Verify Update client API with new client secret for a client who already has overlap secret', 'PRF'), ('Verify Client On boarding for App type as Web with Default Client', 'PRF'), ('Verify Client delegation API :Verify client delegation API for invalid grant type', 'CFE'), ('Verify Client delegation API: Exchange Access token of different client with different scope', 'PRF'), ('Get the short and detailed health status APIs', 'ABX'), ('Verify Entity token for invalid cloud id', 'IAM'), ('Get client details for an on boarded client', 'MIGRA'), ('Verify token exchange API for invalid grant type', 'CFE'), ('Verify Update client API with invalid grant types scope parameter', 'IAM'), ('Verify Token API for refresh token grant type : Verify refresh token API for missing grant type', 'IAM'), ('Verify Smart APP Flows for new HPID user : Sign Up Flow', 'MIGRA'), ('Verify Printer Auth Code Generation API after GCS fix', 'CFE'), ('Verify Client On boarding for App type as Service with Privileged Client', 'PRF'), ('Verify Token API for refresh token grant type : Verify refresh token API with token from different client', 'INRA'), ('Generate authorization code for a device with invalid auth', 'IAM'), ('Verify token exchange API for invalid subject token type', 'IAM'), ('Verify Client On boarding for App type as Browser with Privileged Client', 'PRF'), ('Verify Introspect Token API : Verify Client Credential grant type access token', 'TNT'), ('Verify Create client API with unsupported auth method parameter', 'CFE'), ('Verify Delete client API with Bearer token of unauthorized client', 'PRF'), ('Verify Create client API with unsupported signing algorithm parameter', 'INRA'), ('Generate Entity token with valid request payload', 'MIGRA'), ('Verify Delete client API with Bearer token of unauthorized client', 'PRF'), ('Verify Client delegation API:Exchange Access token of different client with on boarded client scopes with empty scopes in request payload', 'CFE'), ('Verify Update client API with different app type parameter', 'PRF'), ('Verify Create client API without client name', 'INRA'), ('Verify User Delegation API with unsupported grant type', 'ABX'), ('Verify Entity token with invalid access token type in request payload', 'CFE'), ('Verify Create client API with Basic Auth', 'MIGRA'), ('Verify Client On boarding for App type as Service with Default Client', 'IAM'), ('Verify Update client API without grant types scope parameter', 'MIGRA'), ('Verify Granular Scope: Verify granular scope assigned for Refresh Token grant type', 'TENY'), ('Verify Client delegation API : Verify client delegation API for invalid subject token', 'PRF'), ('Verify Introspect Token API : Verify Client Credential grant type access token with valid token type hint', 'PRF'), ('Create access token and refresh token using invalid refresh token', 'ABX'), ('Generate Entity token with empty scope in request payload', 'TENY'), ('Verify Client On boarding for App type as Browser with Privileged Client', 'MIGRA'), ('Create access token and refresh token using valid refresh token', 'MIGRA'), ('Verify Create client API with Bearer Token of invalid client', 'IAM'), ('Get the public keys for validating token', 'IAM'), ('Verify token exchange API for invalid subject token', 'ABX'), ('Verify Get client API with Bearer Token of invalid client', 'PRF'), ('Verify Client delegation API:Exchange Access token of different client with on boarded client scopes without any scope attribute in request payload', 'PRF'), ('Verify Create client API without client Issued at parameter', 'TNT'), ('Verify Granular Scope: Verify granular scope assigned for Scope Reduction Token Exchange grant type', 'PRF'), ('Verify Token API for refresh token grant type : Generate access token with printer refresh token', 'TENY'), ('Exchange HPID token with valid JWT', 'CFE'), ('Verify Delete client API with Basic Auth', 'INRA'), ('Verify Entity token with invalid scope in request payload', 'MIGRA'), ('Verify Client On boarding for App type as Web with Privileged Client', 'CFE'), ('Verify Create client API with Basic Auth', 'TENY'), ('Verify Hashing of old and new Client secrets in Client secret and Secret Overlap tables', 'PRF'), ('Verify Delete client API with Basic Auth', 'TENY'), ('Verify Printer Token Generation API after GCS fix', 'ABX'), ('Verify Granular Scope: Verify granular scope assigned for ID Token Exchange grant type', 'MIGRA'), ('Verify Update client API without contacts parameter', 'TNT'), ('Verify Token API for Client Credentials grant type : Generate token with empty Scopes in request payload', 'IAM'), ('Verify Client On boarding for App type as Native with Privileged Client', 'IAM'), ('Verify Introspect Token API : Verify Client Credential grant type invalid access token', 'MIGRA'), ('Verify Client On boarding for App type as Service with Default Client', 'ABX'), ('Verify Update client API without client Issued at parameter', 'PRF'), ('Get the AuthZ service metadata', 'PRF'), ('Verify User Delegation API with expired subject token', 'ABX'), ('Verify Token API for refresh token grant type : Verify refresh token API for invalid grant type', 'TENY'), ('Generate authorization code for a device with invalid auth', 'PRF'), ('Verify Create client API with expired Bearer Token', 'CFE'), ('Verify Printer Refresh Token Generation API after GCS fix', 'PRF'), ('Verify Update client API without grant type parameter', 'MIGRA'), ('Verify Introspect Token API : Verify Client Credential grant type invalid access token', 'TNT'), ('Verify Client delegation API : Verify client delegation API for invalid client', 'INRA'), ('Get the short and detailed health status APIs', 'IAM'), ('Create access and refresh token using invalid auth code', 'TENY'), ('Verify Smart APP Flows for new HPID user : Sign Up Flow', 'TNT'), ('Verify Update client API with invalid grant types scope parameter', 'IAM'), ('Verify Client On boarding for App type as Browser with Default Client', 'TENY'), ('Verify Update client API with different grant type parameter', 'MIGRA'), ('Verify token exchange API for invalid subject token', 'TNT'), ('Create access and refresh token using already used auth code', 'IAM'), ('Verify Token API for Client Credentials grant type : Verify token API for invalid grant type', 'MIGRA'), ('Verify Update client API with different grant type parameter', 'CFE'), ('Verify Client delegation API : Verify client delegation API for invalid subject token type', 'TNT'), ('Verify Client On boarding for App type as Service with Default Client', 'IAM'), ('Verify Granular Scope: Verify granular scope assigned for Client Delegation Toke Exchange grant type', 'TNT'), ('Verify Get client API with expired Bearer Token', 'CFE'), ('Verify Create client API without grant type parameter', 'ABX'), ('Verify Create client API with unsupported application type parameter', 'PRF'), ('Verify Client delegation API : Verify client delegation API for invalid client', 'ABX'), ('Verify Update client API without grant types scope parameter', 'TENY'), ('Verify token exchange API for invalid grant type', 'ABX'), ('Verify Update client API with different client id issued parameter', 'MIGRA'), ('Verify Introspect Token API : Verify introspect token API for invalid client credentials', 'INRA'), ('Verify Create client API with expired Bearer Token', 'INRA'), ('Verify Get client API with Basic Auth', 'TNT'), ('Verify Create client API without contacts parameter', 'TENY'), ('Verify Update client API with unsupported grant type parameter', 'ABX'), ('Get the short and detailed health status APIs', 'TENY'), ('Verify token exchange API for invalid subject token type', 'CFE'), ('Create access and refresh token using invalid auth code', 'PRF'), ('Delete client details for an on boarded client', 'MIGRA'), ('Verify Create client API without grant types scope parameter', 'INRA'), ('Verify Printer Token Generation API after GCS fix', 'CFE'), ('Verify Update client API with unsupported application type parameter', 'IAM'), ('Verify Get client API with Bearer token of unauthorized client', 'PRF')]\n"
     ]
    }
   ],
   "source": [
    "output = pd.DataFrame(y_pred)\n",
    "output.rename(columns={1:'Target'},inplace=True)\n",
    "# output = pd.concat([dataset1[dataset1.ID.isin(pd.DataFrame(X_test)[1])], output], axis=1)\n",
    "output = pd.concat([pd.DataFrame(X_test)[[1,7,9]],output], axis=1)\n",
    "\n",
    "output.dropna(inplace=True)\n",
    "output.drop_duplicates(subset=[1], inplace=True)\n",
    "output.rename(columns={1:'ID',7:\"Modules\",9:\"Scripts\",'Target':\"Target\"},inplace=True)\n",
    "# output.to_csv('output.csv')\n",
    "master_dataframe = output\n",
    "\n",
    "master_dataframe = master_dataframe.astype({\"ID\": int})\n",
    "# master_dataframe.dtypes\n",
    "# master_dataframe.set_index('ID').join(final.set_index('ID'))\n",
    "\n",
    "master_dataframe = pd.merge(left=final[['ID', 'Test Case Title']], right=master_dataframe, how='right', left_on='ID', right_on='ID')\n",
    "master_dataframe.drop_duplicates(subset=['ID'], inplace=True)\n",
    "#Final format\n",
    "\n",
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "timestamp = str(now.strftime(\"%Y%m%d_%H-%M-%S\"))\n",
    "date =  str(now.strftime(\"%Y%m%d\"))\n",
    "\n",
    "#creating output folder as per the today's date\n",
    "import os\n",
    "output_folder = '../'+'output_'+date\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "final_output_file = output_folder + '/FinalOutput_'+timestamp+'.xlsx'\n",
    "writer = pd.ExcelWriter(final_output_file, engine='xlsxwriter')\n",
    "\n",
    "pd.DataFrame(master_dataframe.iloc[:, 0:2]).to_excel(writer,\n",
    "    sheet_name=\"Master_Output\",\n",
    "    index=False)\n",
    "\n",
    "\n",
    "\n",
    "df = master_dataframe\n",
    "m_tc = []\n",
    "a_tc = []\n",
    "# if limit == 0:\n",
    "for i in range(len(df.iloc[:,0])):\n",
    "    if df.iloc[i,3] == \"Manual Testing\":\n",
    "        # m_tc.append((df.iloc[i,0], df.iloc[i,1], df.iloc[i,2]))\n",
    "        m_tc.append((df.iloc[i,0], df.iloc[i,1], df.iloc[i,2]))\n",
    "    else:\n",
    "        a_tc.append((df.iloc[i,1], df.iloc[i,2]))\n",
    "print(\"---------Manual List----------\")\n",
    "print(m_tc)\n",
    "print(\"---------Auto List----------\")\n",
    "print(a_tc)\n",
    "# else:\n",
    "#     for i in range(len(df['Test ID'])):\n",
    "#         if df['Automation Script Name'][i] == \"Manual Testing\":\n",
    "#             m_tc.append((df['Test ID'][i], df['Test case Title'][i], df['Module'][i]))\n",
    "#         else:\n",
    "#             a_tc.append((df['Automation Script Name'][i], df['Module'][i]))\n",
    "\n",
    "df_auto = pd.DataFrame(set(a_tc), columns=[\"Module\", \"Automation Script Name\"])\n",
    "df_auto.index += 1\n",
    "df_auto.index.name=\"S.No.\"\n",
    "df_auto.to_excel(writer, sheet_name=\"Automation_Scripts\")\n",
    "df_manual = pd.DataFrame(m_tc, columns=[\"Test ID\", \"Test Case Title\",\"Module\"])\n",
    "df_manual.index += 1\n",
    "df_manual.index.name = \"S.No.\"\n",
    "df_manual.to_excel(writer, sheet_name=\"Manual_TC\")\n",
    "\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "56f8fca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df.iloc[:,0])):\n",
    "    if df.iloc[i,2] == \"Manual Testing\":\n",
    "        # m_tc.append((df.iloc[i,0], df.iloc[i,1], df.iloc[i,2]))\n",
    "        m_tc.append((df.iloc[i,0], df.iloc[i,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "9001817f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('8062', 'PRF'),\n",
       " ('8059', 'PRF'),\n",
       " ('8031', 'IAM'),\n",
       " ('8045', 'CFE'),\n",
       " ('7900', 'CFE'),\n",
       " ('7608', 'TNT'),\n",
       " ('8057', 'CFE'),\n",
       " ('7535', 'PRF'),\n",
       " ('7901', 'INRA'),\n",
       " ('8041', 'IAM'),\n",
       " ('7984', 'ABX'),\n",
       " ('8056', 'TNT'),\n",
       " ('7545', 'CFE'),\n",
       " ('7931', 'TENY'),\n",
       " ('7531', 'ABX'),\n",
       " ('8054', 'ABX'),\n",
       " ('8047', 'PRF'),\n",
       " ('8033', 'PRF'),\n",
       " ('7930', 'ABX'),\n",
       " ('7983', 'TNT'),\n",
       " ('7915', 'PRF'),\n",
       " ('7513', 'CFE'),\n",
       " ('7552', 'TNT'),\n",
       " ('7520', 'PRF'),\n",
       " ('7905', 'ABX'),\n",
       " ('8063', 'IAM'),\n",
       " ('7605', 'ABX'),\n",
       " ('8043', 'PRF'),\n",
       " ('8051', 'INRA'),\n",
       " ('7979', 'TNT'),\n",
       " ('8060', 'TNT'),\n",
       " ('7906', 'TENY'),\n",
       " ('8074', 'TENY'),\n",
       " ('8066', 'CFE'),\n",
       " ('8028', 'PRF'),\n",
       " ('8053', 'IAM'),\n",
       " ('8048', 'ABX'),\n",
       " ('8065', 'PRF'),\n",
       " ('8023', 'CFE'),\n",
       " ('7528', 'INRA'),\n",
       " ('7553', 'TNT'),\n",
       " ('7536', 'TNT'),\n",
       " ('8058', 'TNT'),\n",
       " ('7518', 'ABX'),\n",
       " ('8042', 'ABX'),\n",
       " ('8022', 'CFE'),\n",
       " ('8069', 'PRF'),\n",
       " ('8070', 'ABX'),\n",
       " ('8029', 'INRA'),\n",
       " ('7503', 'PRF'),\n",
       " ('7517', 'PRF'),\n",
       " ('8073', 'INRA'),\n",
       " ('8040', 'PRF'),\n",
       " ('8044', 'CFE'),\n",
       " ('8011', 'PRF'),\n",
       " ('7991', 'PRF'),\n",
       " ('8049', 'TENY'),\n",
       " ('8062', 'PRF'),\n",
       " ('8059', 'PRF'),\n",
       " ('8031', 'IAM'),\n",
       " ('8045', 'CFE'),\n",
       " ('7900', 'CFE'),\n",
       " ('7608', 'TNT'),\n",
       " ('8057', 'CFE'),\n",
       " ('7535', 'PRF'),\n",
       " ('7901', 'INRA'),\n",
       " ('8041', 'IAM'),\n",
       " ('7984', 'ABX'),\n",
       " ('8056', 'TNT'),\n",
       " ('7545', 'CFE'),\n",
       " ('7931', 'TENY'),\n",
       " ('7531', 'ABX'),\n",
       " ('8054', 'ABX'),\n",
       " ('8047', 'PRF'),\n",
       " ('8033', 'PRF'),\n",
       " ('7930', 'ABX'),\n",
       " ('7983', 'TNT'),\n",
       " ('7915', 'PRF'),\n",
       " ('7513', 'CFE'),\n",
       " ('7552', 'TNT'),\n",
       " ('7520', 'PRF'),\n",
       " ('7905', 'ABX'),\n",
       " ('8063', 'IAM'),\n",
       " ('7605', 'ABX'),\n",
       " ('8043', 'PRF'),\n",
       " ('8051', 'INRA'),\n",
       " ('7979', 'TNT'),\n",
       " ('8060', 'TNT'),\n",
       " ('7906', 'TENY'),\n",
       " ('8074', 'TENY'),\n",
       " ('8066', 'CFE'),\n",
       " ('8028', 'PRF'),\n",
       " ('8053', 'IAM'),\n",
       " ('8048', 'ABX'),\n",
       " ('8065', 'PRF'),\n",
       " ('8023', 'CFE'),\n",
       " ('7528', 'INRA'),\n",
       " ('7553', 'TNT'),\n",
       " ('7536', 'TNT'),\n",
       " ('8058', 'TNT'),\n",
       " ('7518', 'ABX'),\n",
       " ('8042', 'ABX'),\n",
       " ('8022', 'CFE'),\n",
       " ('8069', 'PRF'),\n",
       " ('8070', 'ABX'),\n",
       " ('8029', 'INRA'),\n",
       " ('7503', 'PRF'),\n",
       " ('7517', 'PRF'),\n",
       " ('8073', 'INRA'),\n",
       " ('8040', 'PRF'),\n",
       " ('8044', 'CFE'),\n",
       " ('8011', 'PRF'),\n",
       " ('7991', 'PRF'),\n",
       " ('8049', 'TENY')]"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_tc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "08779a91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 7500, 8.2, ..., 0, 0, 0],\n",
       "       [1, 7501, 8.2, ..., 0, 0, 0],\n",
       "       [2, 7502, 8.2, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [1216, 8046, '5.3.2', ..., 0, 0, 0],\n",
       "       [1217, 8047, '5.3.2', ..., 0, 0, 0],\n",
       "       [1218, 8048, '5.3.2', ..., 0, 0, 0]], dtype=object)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "e3e415b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       ID                                    Test Case Title Modules  \\\n",
      "13   7505  Verify Client delegation API:Exchange Access t...     ABX   \n",
      "31   7664  Verify Refresh Token for Parallel Login : Veri...   MIGRA   \n",
      "60   7535  Create access and refresh tokens using invalid...     PRF   \n",
      "69   7999                     Get the AuthZ service metadata    INRA   \n",
      "86   7508  Verify Client delegation API :Verify client de...     TNT   \n",
      "95   8041    Verify token exchange API for missing attribute     IAM   \n",
      "104  7997  Verify Smart APP Flows for new HPID user : Sig...    INRA   \n",
      "114  7996  Verify Refresh Token for Parallel Login : Veri...   MIGRA   \n",
      "121  7554  Verify Scope Reduction API : Exchange ID token...     PRF   \n",
      "142  7545  Verify Introspect Token API : Verify Client Cr...     CFE   \n",
      "156  7500      Get the short and detailed health status APIs     ABX   \n",
      "162  7524           Verify Entity token for invalid cloud id     IAM   \n",
      "171  7542   Verify token exchange API for invalid grant type     CFE   \n",
      "202  7665  Verify Smart APP Flows for new HPID user : Sig...   MIGRA   \n",
      "219  7873  Verify token exchange API for invalid subject ...     IAM   \n",
      "225  7877  Verify Introspect Token API : Verify Client Cr...     TNT   \n",
      "237  7523   Generate Entity token with valid request payload   MIGRA   \n",
      "266  7527  Verify Entity token with invalid access token ...     CFE   \n",
      "287  7513  Verify Token API for Client Credentials grant ...     CFE   \n",
      "293  7552  Verify Scope Reduction API : Exchange Access t...     TNT   \n",
      "299  7509  Verify Client delegation API : Verify client d...     PRF   \n",
      "305  7878  Verify Introspect Token API : Verify Client Cr...     PRF   \n",
      "308  7538  Create access token and refresh token using in...     ABX   \n",
      "314  7525  Generate Entity token with empty scope in requ...    TENY   \n",
      "323  7520  Verify Token API for refresh token grant type ...     PRF   \n",
      "332  7537  Create access token and refresh token using va...   MIGRA   \n",
      "341  7502           Get the public keys for validating token     IAM   \n",
      "359  7544  Verify token exchange API for invalid subject ...     ABX   \n",
      "393  7515  Verify Token API for refresh token grant type ...    TENY   \n",
      "402  7539                 Exchange HPID token with valid JWT     CFE   \n",
      "414  7526  Verify Entity token with invalid scope in requ...   MIGRA   \n",
      "461  7880  Verify Introspect Token API : Verify Client Cr...   MIGRA   \n",
      "475  7528  Verify Entity token with invalid grant type ty...    INRA   \n",
      "481  7501                     Get the AuthZ service metadata     PRF   \n",
      "494  7553  Verify Scope Reduction API : Exchange Access t...     TNT   \n",
      "500  7522  Generate authorization code for a device with ...     PRF   \n",
      "516  7548  Verify Introspect Token API : Verify Client Cr...     TNT   \n",
      "526  7536  Create access and refresh token using invalid ...     TNT   \n",
      "535  7998      Get the short and detailed health status APIs     IAM   \n",
      "542  7865  Create access and refresh token using invalid ...    TENY   \n",
      "545  8163  Verify Smart APP Flows for new HPID user : Sig...     TNT   \n",
      "548  7518  Verify Token API for refresh token grant type ...     ABX   \n",
      "554  8042  Verify token exchange API for invalid subject ...     ABX   \n",
      "575  7876  Verify token exchange API for invalid subject ...     TNT   \n",
      "578  7866  Create access and refresh token using already ...     IAM   \n",
      "591  7507  Verify Client delegation API : Verify client d...     TNT   \n",
      "606  7503  Verify Client delegation API: Exchange Access ...     PRF   \n",
      "624  7506  Verify Client delegation API : Verify client d...     ABX   \n",
      "630  7517  Verify Token API for refresh token grant type ...     PRF   \n",
      "640  7874   Verify token exchange API for invalid grant type     ABX   \n",
      "649  7550  Verify Introspect Token API : Verify introspec...    INRA   \n",
      "661  8040   Verify token exchange API for invalid grant type     PRF   \n",
      "680  7666      Get the short and detailed health status APIs    TENY   \n",
      "683  7541  Verify token exchange API for invalid subject ...     CFE   \n",
      "693  7533  Create access and refresh token using invalid ...     PRF   \n",
      "\n",
      "            Scripts  Target  \n",
      "13     Script ABX02       1  \n",
      "31   Script MIGRA22       1  \n",
      "60   Manual Testing       1  \n",
      "69    Script INRA78       1  \n",
      "86     Script TNT36       1  \n",
      "95   Manual Testing       1  \n",
      "104   Script INRA77       1  \n",
      "114  Script MIGRA92       1  \n",
      "121    Script PRF28       1  \n",
      "142  Manual Testing       1  \n",
      "156    Script ABX01       1  \n",
      "162    Script IAM14       1  \n",
      "171    Script CFE05       1  \n",
      "202  Script MIGRA21       1  \n",
      "219    Script IAM60       1  \n",
      "225   Script TNT122       1  \n",
      "237  Script MIGRA23       1  \n",
      "266    Script CFE06       1  \n",
      "287  Manual Testing       1  \n",
      "293  Manual Testing       1  \n",
      "299    Script PRF29       1  \n",
      "305    Script PFR95       1  \n",
      "308    Script ABX04       1  \n",
      "314   Script TENY34       1  \n",
      "323  Manual Testing       1  \n",
      "332  Script MIGRA22       1  \n",
      "341    Script IAM12       1  \n",
      "359    Script ABX01       1  \n",
      "393   Script TENY31       1  \n",
      "402    Script CFE07       1  \n",
      "414  Script MIGRA21       1  \n",
      "461  Script MIGRA88       1  \n",
      "475  Manual Testing       1  \n",
      "481    Script PRF27       1  \n",
      "494  Manual Testing       1  \n",
      "500    Script PRF27       1  \n",
      "516    Script TNT38       1  \n",
      "526  Manual Testing       1  \n",
      "535    Script IAM60       1  \n",
      "542  Script TENY110       1  \n",
      "545   Script TNT116       1  \n",
      "548  Manual Testing       1  \n",
      "554  Manual Testing       1  \n",
      "575   Script TNT118       1  \n",
      "578    Script IAM59       1  \n",
      "591    Script TNT37       1  \n",
      "606  Manual Testing       1  \n",
      "624    Script ABX03       1  \n",
      "630  Manual Testing       1  \n",
      "640    Script ABX41       1  \n",
      "649   Script INRA17       1  \n",
      "661  Manual Testing       1  \n",
      "680   Script TENY31       1  \n",
      "683    Script CFE08       1  \n",
      "693    Script PRF26       1  \n"
     ]
    }
   ],
   "source": [
    "delete_row = master_dataframe[master_dataframe[\"Target\"]==0].index\n",
    "df_del = master_dataframe.drop(delete_row)\n",
    "print(df_del)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "4e3024f4",
   "metadata": {},
   "outputs": [
    {
     "ename": "XLRDError",
     "evalue": "Unsupported format, or corrupt file: Expected BOF record; found b'<html xm'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mXLRDError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8492/1893975261.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'C:/Users/azure/Desktop/Defects/JMP JIRA 2022-02-18T14_34_30+0100.xls'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'xlrd'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\SmartTest\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\SmartTest\\lib\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options)\u001b[0m\n\u001b[0;32m    362\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    363\u001b[0m         \u001b[0mshould_close\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 364\u001b[1;33m         \u001b[0mio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    365\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    366\u001b[0m         raise ValueError(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\SmartTest\\lib\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, path_or_buffer, engine, storage_options)\u001b[0m\n\u001b[0;32m   1231\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstorage_options\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1232\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1233\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engines\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_io\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1234\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1235\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__fspath__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\SmartTest\\lib\\site-packages\\pandas\\io\\excel\\_xlrd.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, filepath_or_buffer, storage_options)\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0merr_msg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Install xlrd >= 1.0.0 for Excel support\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mimport_optional_dependency\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"xlrd\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextra\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\SmartTest\\lib\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, filepath_or_buffer, storage_options)\u001b[0m\n\u001b[0;32m    418\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    419\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 420\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_workbook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    421\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    422\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\SmartTest\\lib\\site-packages\\pandas\\io\\excel\\_xlrd.py\u001b[0m in \u001b[0;36mload_workbook\u001b[1;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"read\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mopen_workbook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_contents\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mopen_workbook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\SmartTest\\lib\\site-packages\\xlrd\\__init__.py\u001b[0m in \u001b[0;36mopen_workbook\u001b[1;34m(filename, logfile, verbosity, use_mmap, file_contents, encoding_override, formatting_info, on_demand, ragged_rows, ignore_workbook_corruption)\u001b[0m\n\u001b[0;32m    180\u001b[0m         \u001b[0mon_demand\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mon_demand\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[0mragged_rows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mragged_rows\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m         \u001b[0mignore_workbook_corruption\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mignore_workbook_corruption\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m     )\n\u001b[0;32m    184\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\SmartTest\\lib\\site-packages\\xlrd\\book.py\u001b[0m in \u001b[0;36mopen_workbook_xls\u001b[1;34m(filename, logfile, verbosity, use_mmap, file_contents, encoding_override, formatting_info, on_demand, ragged_rows, ignore_workbook_corruption)\u001b[0m\n\u001b[0;32m     77\u001b[0m         \u001b[0mt1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mperf_counter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[0mbk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_time_stage_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mt0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m         \u001b[0mbiff_version\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetbof\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXL_WORKBOOK_GLOBALS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mbiff_version\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mXLRDError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Can't determine file's BIFF version\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\SmartTest\\lib\\site-packages\\xlrd\\book.py\u001b[0m in \u001b[0;36mgetbof\u001b[1;34m(self, rqd_stream)\u001b[0m\n\u001b[0;32m   1282\u001b[0m             \u001b[0mbof_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Expected BOF record; met end of file'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1283\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mopcode\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbofcodes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1284\u001b[1;33m             \u001b[0mbof_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Expected BOF record; found %r'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmem\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msavpos\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0msavpos\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1285\u001b[0m         \u001b[0mlength\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget2bytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1286\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlength\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mMY_EOF\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\SmartTest\\lib\\site-packages\\xlrd\\book.py\u001b[0m in \u001b[0;36mbof_error\u001b[1;34m(msg)\u001b[0m\n\u001b[0;32m   1276\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1277\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mbof_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1278\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mXLRDError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Unsupported format, or corrupt file: '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1279\u001b[0m         \u001b[0msavpos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_position\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1280\u001b[0m         \u001b[0mopcode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget2bytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mXLRDError\u001b[0m: Unsupported format, or corrupt file: Expected BOF record; found b'<html xm'"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel('C:/Users/azure/Desktop/Defects/JMP JIRA 2022-02-18T14_34_30+0100.xls', index_col=0, engine='xlrd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "e4b817bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xlrd\n",
      "  Downloading xlrd-2.0.1-py2.py3-none-any.whl (96 kB)\n",
      "Installing collected packages: xlrd\n",
      "Successfully installed xlrd-2.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install xlrd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4900051",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
